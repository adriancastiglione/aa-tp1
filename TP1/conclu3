#### Conclusiones Grid Search

Presentamos a continuación los diferentes modelos utilizados, con los hiper-parámetros barridos, el mejor set, y la performance de dicho set. En el modelo LinearSVC se realizaron dos barridos. En el modelo GaussianNB todos los barridos obtuvieron exactamente la misma performance. En el modelo LDA presentamos la performance de todos los dets de hiper-parámetros.

KNN: 
Tuned parameters: {'n_neighbors': range(1, 121, 10), 'weights': ['uniform', 'distance'], 'p': range(1, 3)}
Best parameters set: {'n_neighbors': 51, 'p': 1, 'weights': 'distance'}
Best score: 0.885 (+/-0.121)

Árboles: 
Tuned parameters: {'max_depth': range(1,6), 'criterion': ['gini', 'entropy']}
Best parameters set: {'criterion': 'entropy', 'max_depth': 2}
Best score: 0.765 (+/-0.096)

LDA: 
Tuned parameters: {'solver': ['svd']}, {'solver': ['lsqr'], 'shrinkage': [None,'auto']}
Best parameters set: {'shrinkage': 'auto', 'solver': 'lsqr'}
Best score: 0.875 (+/-0.107)
Other scores:
0.538 (+/-0.070) for {'solver': 'svd'}
0.480 (+/-0.206) for {'shrinkage': None, 'solver': 'lsqr'}

GaussianNB: 
Tuned parameters: {'priors': [None, [0.1, 0.9], [0.2, 0.8], [0.3, 0.7], [0.4, 0.6], [0.5, 0.5], [0.6, 0.4], [0.7, 0.3], [0.8, 0.2], [0.9, 0.1]]}
Best parameters set: {'priors': None}
Best score: 0.877 (+/-0.083)

LinearSVC:
Tuned parameters: {'C': np.logspace(-4, 4, num=49, base=10.0)}
&
Tuned parameters: {'C': np.logspace(-3, 2, num=49, base=10.0)}
Best parameters set: {'C': 0.001539926526059492}
Best score: 0.887 (+/-0.100)

Conclusiones: 
Exceptuando el método de árboles, en todos los métodos obtenemos una performance similar de aproximadamente 0.88 +/- 0.1.

En el caso del método LDA vemos que la performance mejora considerablemente en el mejor set contra los otros dos. En la documentación del algoritmo encontramos que la herramienta "shrinkage" mejora la estimación de la matriz de covarianza en el caso en que el número de instancias de entrenamiento es chico comparado con el número de atributos. En nuestro caso tenemos 250 instancias de entrenamiento y 200 atributos, por lo que estamso cerca de dicha condición

El mejor resultado obtenido lo encontramos en el modelo LinearSVC, con un margen pequeño . Esto puede deberse a que el problema es linealmente separable, y el límite de performance alcanzado en los modelos (~12% error) puede deberse a ruido inherente a los datos.

Al ser separable en más de una dimension, el método de árboles no es muy bueno encontrando la frontera.


EJERCICO EXTRA

Presentamos los tres modelos en los que realizamos RandomSearch, con el mejor set de hiper-parámetros, la performance de dicho set, y el tiempo de ejecución, comparado con el tiempo de ejecución en GridSearch.
En estos casos en particular, el RandomSearch no mejora de manera notable el tiempo de cómputo ni la búsqueda de mejore combinaciones de parámetros. 
Esto puede deberse a que realizar un barrido aleatorio mejora la elección de punto en el espacio de hiperparámetros cuando éste tiene muchas dimensiones, y cada dimensión muchos o infinitos valores. No es el caso en estos modelos.

KNN: 
Best score: 0.885 (+/-0.121) for {'weights': 'distance', 'p': 1, 'n_neighbors': 51}
Wall time: 7.01 s
GRID: Wall time: 7.56 s

Arboles:
Best score: 0.765 (+/-0.096) for {'max_depth': 2, 'criterion': 'entropy'}
Wall time: 1.89 s
GRID: Wall time: 1.6 s

SVC
Best score: 0.887 (+/-0.100) for {'C': 0.0015262013596464125}
Wall time: 1.86 s
GRID: Wall time: 1.82 s
