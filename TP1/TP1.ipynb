{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 1 \n",
    "### Clasificación sobre datos simulados. \n",
    "\n",
    "## Introducción\n",
    "Para este trabajo, hemos creado una función generadora de minions. Sobre cada minion, hemos medido 200 características que representan habilidades que poseen en distintas tareas (relacionadas al Mal).  \n",
    "\n",
    "El doctor Nefario ha ideado una fórmula para determinar si un minion es o no apto para concretar su plan para conquistar el mundo. De esta manera ha etiquetado más de 500 minions. Lamentablemente, ha perdido dicha fórmula y necesita seguir decidiendo si nuevos minions son o no aptos para su macabro plan.\n",
    "\n",
    "Es por esto que nuestro objetivo será construir clasificadores que estimen lo mejor posible la probabilidad de que nuevos minions sean o no aptos para concretar el plan de conquista y así facilitarle las cosas al doctor Nefario.\n",
    "\n",
    "Por otra parte, ya que el doctor Nefario tuvo problemas con equipos que sobreestiman sus resultados, decidió guardarse varias etiquetas extra que no compartirá con nadie, y que luego utilizará para elegir al mejor equipo, al cual contratará para (de una vez por todas) conquistar el mundo. \n",
    "\n",
    "\n",
    "En concreto:\n",
    "\n",
    "Tendrán disponible una matriz de datos $X$ de $500$ filas en donde cada fila $x^{(i)}$ representa un vector de $200$ características de cada instancia. Es decir, $\\textbf{x}^{(i)} = x_1^{(i)}, \\dots, x_{200}^{(i)}$ con $i$ entre $1$ y $500$. Además, tendrán y, un vector de $500$ posiciones con dos posibles valores: $True$ y $False$. \n",
    "\n",
    "Por otra parte, tendrán disponibles más instancias de evaluación $X_{competencia}$ sin las respectivas etiquetas que utilizaremos para evaluar sus resultados. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PREAMBULOS\n",
    "%matplotlib inline\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from IPython.display import display, HTML\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as  pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "pd.set_option('precision', 4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.ensemble\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.svm\n",
    "\n",
    "import sklearn.model_selection\n",
    "from scipy.stats import randint as sp_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4914</td>\n",
       "      <td>0.1644</td>\n",
       "      <td>1.2315</td>\n",
       "      <td>1.2429</td>\n",
       "      <td>1.5576</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.1983</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>1.5375</td>\n",
       "      <td>-0.7727</td>\n",
       "      <td>-0.1401</td>\n",
       "      <td>2.0871</td>\n",
       "      <td>-0.8312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.2749</td>\n",
       "      <td>0.2780</td>\n",
       "      <td>-1.3108</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>-0.5503</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>-0.4478</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2190</td>\n",
       "      <td>-0.3190</td>\n",
       "      <td>-0.6446</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>-1.2374</td>\n",
       "      <td>-1.3291</td>\n",
       "      <td>-1.3265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.2243</td>\n",
       "      <td>-0.5710</td>\n",
       "      <td>-0.2712</td>\n",
       "      <td>-0.1328</td>\n",
       "      <td>-1.0045</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>-1.4507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>-0.1989</td>\n",
       "      <td>-0.0393</td>\n",
       "      <td>-0.5866</td>\n",
       "      <td>2.2507</td>\n",
       "      <td>1.4925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5853</td>\n",
       "      <td>-0.8532</td>\n",
       "      <td>-0.2723</td>\n",
       "      <td>-0.5493</td>\n",
       "      <td>-2.9824</td>\n",
       "      <td>-0.1697</td>\n",
       "      <td>-0.0430</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6488</td>\n",
       "      <td>-0.7363</td>\n",
       "      <td>-0.8866</td>\n",
       "      <td>-1.2717</td>\n",
       "      <td>-0.1493</td>\n",
       "      <td>0.2007</td>\n",
       "      <td>-1.4820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.4155</td>\n",
       "      <td>1.4187</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>-0.7993</td>\n",
       "      <td>0.2939</td>\n",
       "      <td>-0.1796</td>\n",
       "      <td>-0.7140</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1314</td>\n",
       "      <td>-0.4230</td>\n",
       "      <td>-0.2685</td>\n",
       "      <td>0.3045</td>\n",
       "      <td>-1.2245</td>\n",
       "      <td>-1.9421</td>\n",
       "      <td>1.5186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.2516</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>-1.1980</td>\n",
       "      <td>0.4577</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.2476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5829</td>\n",
       "      <td>-0.5494</td>\n",
       "      <td>0.4607</td>\n",
       "      <td>1.2182</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>3.0034</td>\n",
       "      <td>-0.0344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.6246</td>\n",
       "      <td>-1.0590</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>-1.6657</td>\n",
       "      <td>0.3982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1075</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>-0.4229</td>\n",
       "      <td>0.3977</td>\n",
       "      <td>-0.0808</td>\n",
       "      <td>-1.7054</td>\n",
       "      <td>-0.4786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>-0.9023</td>\n",
       "      <td>-1.7792</td>\n",
       "      <td>-0.0121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8491</td>\n",
       "      <td>0.7469</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>-1.0090</td>\n",
       "      <td>0.3317</td>\n",
       "      <td>-1.7513</td>\n",
       "      <td>-0.5397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>1.7056</td>\n",
       "      <td>0.3418</td>\n",
       "      <td>-0.8350</td>\n",
       "      <td>0.4068</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0130</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>-1.6642</td>\n",
       "      <td>2.5117</td>\n",
       "      <td>-0.0118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.4028</td>\n",
       "      <td>-0.6085</td>\n",
       "      <td>1.0845</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3587</td>\n",
       "      <td>-0.3121</td>\n",
       "      <td>-0.7630</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.6161</td>\n",
       "      <td>-0.0902</td>\n",
       "      <td>-1.0215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1       2       3       4       5       6   ...       193  \\\n",
       "index                                                           ...             \n",
       "0      1.4914  0.1644  1.2315  1.2429  1.5576  0.0455  0.1302   ...   -1.1983   \n",
       "1     -0.2749  0.2780 -1.3108  0.6801 -0.5503  0.6359 -0.4478   ...    1.2190   \n",
       "2     -0.2243 -0.5710 -0.2712 -0.1328 -1.0045  0.9315 -1.4507   ...    0.9459   \n",
       "3      0.5853 -0.8532 -0.2723 -0.5493 -2.9824 -0.1697 -0.0430   ...    1.6488   \n",
       "4     -1.4155  1.4187  0.6027 -0.7993  0.2939 -0.1796 -0.7140   ...    1.1314   \n",
       "...       ...     ...     ...     ...     ...     ...     ...   ...       ...   \n",
       "495    0.2516  0.9375 -1.1980  0.4577  0.9287  0.5373  0.2476   ...    0.5829   \n",
       "496    0.6246 -1.0590  0.9491  0.2687  0.6610 -1.6657  0.3982   ...   -0.1075   \n",
       "497    0.2677  0.1802  0.7154  0.3542 -0.9023 -1.7792 -0.0121   ...    0.8491   \n",
       "498    0.1926  0.7834  1.7056  0.3418 -0.8350  0.4068  0.0495   ...   -0.0130   \n",
       "499    0.0427  0.4028 -0.6085  1.0845  0.1033  0.2698 -0.8598   ...   -0.3587   \n",
       "\n",
       "          194     195     196     197     198     199  \n",
       "index                                                  \n",
       "0     -0.0118  1.5375 -0.7727 -0.1401  2.0871 -0.8312  \n",
       "1     -0.3190 -0.6446 -0.0061 -1.2374 -1.3291 -1.3265  \n",
       "2      0.1430 -0.1989 -0.0393 -0.5866  2.2507  1.4925  \n",
       "3     -0.7363 -0.8866 -1.2717 -0.1493  0.2007 -1.4820  \n",
       "4     -0.4230 -0.2685  0.3045 -1.2245 -1.9421  1.5186  \n",
       "...       ...     ...     ...     ...     ...     ...  \n",
       "495   -0.5494  0.4607  1.2182  0.1025  3.0034 -0.0344  \n",
       "496    0.8993 -0.4229  0.3977 -0.0808 -1.7054 -0.4786  \n",
       "497    0.7469  0.2071 -1.0090  0.3317 -1.7513 -0.5397  \n",
       "498    0.1483  0.5019 -0.0020 -1.6642  2.5117 -0.0118  \n",
       "499   -0.3121 -0.7630  0.6525  0.6161 -0.0902 -1.0215  \n",
       "\n",
       "[500 rows x 200 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       output\n",
       "index        \n",
       "0           0\n",
       "1           0\n",
       "2           0\n",
       "3           0\n",
       "4           1\n",
       "...       ...\n",
       "495         1\n",
       "496         0\n",
       "497         1\n",
       "498         0\n",
       "499         0\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carga de datos\n",
    "X = pd.read_csv(\"X.csv\", index_col=\"index\")\n",
    "y = pd.read_csv(\"y.csv\", index_col=\"index\", dtype=int)  # Cargamos los valores booleanos (True y False)\n",
    "                                                        # como números (1 y 0) para facilitar el manejo luego. \n",
    "    \n",
    "X_competencia = pd.read_csv(\"X_competencia1.csv\", index_col=\"index\")\n",
    "y_competencia_ejemplo = pd.read_csv(\"y_competencia_ejemplo.csv\", index_col=\"index\")\n",
    "display(X)\n",
    "display(y)\n",
    "\n",
    "# Descomentar si quieren ver los datos para la competencia:\n",
    "# display(X_competencia) \n",
    "# display(y_competencia_ejemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "### Separación de datos\n",
    "\n",
    "Contarán con una cantidad limitada de datos, por lo cual es importante tomar una buena decisión en el momento de empezar a utilizarlos. En este punto pedimos que evalúen cómo separar sus datos para desarrollo y para evaluación tomando en cuenta la competencia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_dev: (250, 200), y_dev: (250, 1) para desarrollo\n",
      "X_eval: (250, 200), y_eval: (250, 1) para evaluación\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAADFCAYAAAAhb/tIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nic4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb09a828588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    }
   ],
   "source": [
    "# EJERCICIO 1. \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "########################################################\n",
    "## AQUI VA SU CODIGO\n",
    "#X_dev, X_eval, y_dev, y_eval = X, X, y, y  # cambiar esta línea si lo consideran necesario\n",
    "\n",
    "X_dev, X_eval, y_dev, y_eval = sklearn.model_selection.train_test_split(\n",
    "    X, y, random_state=1234, test_size=0.5)\n",
    "\n",
    "# Objetivo: variables X_dev, X_eval, y_dev e y_eval asignadas\n",
    "#########################################################\n",
    "\n",
    "\n",
    "print(\"X_dev: {}, y_dev: {} para desarrollo\".format(X_dev.shape, y_dev.shape))\n",
    "print(\"X_eval: {}, y_eval: {} para evaluación\".format(X_eval.shape, y_eval.shape))\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(np.array(y_dev))  # muestra un histograma para la distribución de y.\n",
    "plt.show()\n",
    "print(y_dev['output'].sum()) #118 de los de dev son true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "### Construcción de modelos\n",
    "\n",
    "Para este punto, la tarea consiste en construir y evaluar modelos de tipo árbol de decisión, de manera de obtener una estimación realista de la performance de los mismos. \n",
    "\n",
    "1. Entrenar un árbol de decisión con altura máxima 3 y el resto de los hiperparámetros en default. \n",
    "2. Estimar la performance del modelo utilizando K-fold cross validation con K = 5, con las métricas “Accuracy” y “ROC AUC”. Para ello, se pide medir la performance en cada partición tanto sobre el fold de validación como sobre los folds de entrenamiento. Luego, completar la primera tabla.\n",
    "3. Entrenar árboles de decisión para cada una de las siguientes combinaciones y completar la segunda tabla.\n",
    "\n",
    "----\n",
    "\n",
    "**EJERCICIO EXTRA: Usar la implementación de árboles de decisión que realizaron para la guía de ejercicios de la materia. Adaptarla para que cumpla con la interfaz requerida por sklearn, asegurarse de que funcione con variables continuas y reproducir las tablas anteriores.   **\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 1 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validación)</th>\n",
       "      <th>AUC ROC (training)</th>\n",
       "      <th>AUC ROC (validación)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Permutación</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.9026</td>\n",
       "      <td>0.6779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.9006</td>\n",
       "      <td>0.6489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.8490</td>\n",
       "      <td>0.5682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>0.7603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.8698</td>\n",
       "      <td>0.7800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy (training)  Accuracy (validación)  AUC ROC (training)  \\\n",
       "Permutación                                                                   \n",
       "1                          0.900                   0.68              0.9026   \n",
       "2                          0.900                   0.68              0.9006   \n",
       "3                          0.845                   0.56              0.8490   \n",
       "4                          0.875                   0.76              0.8763   \n",
       "5                          0.875                   0.78              0.8698   \n",
       "\n",
       "             AUC ROC (validación)  \n",
       "Permutación                        \n",
       "1                          0.6779  \n",
       "2                          0.6489  \n",
       "3                          0.5682  \n",
       "4                          0.7603  \n",
       "5                          0.7800  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAEGCAYAAAAAHm2OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XtYVWXaP/DvzRkEUZBQUYTUDWxA\nRYjEQ+X7aoOV1kSTpzKbwNSxNCt1mik7TE7H38yLppfmqGFWkpZ56OTVOGY6pqApZ0VTIQUUEUEQ\nBZ7fH+yNWxaHDWxA4Pu5Lq/2XuvZa90uNb57HZ5blFIgIiIiMmXV1gUQERHRrYcBgYiIiDQYEIiI\niEiDAYGIiIg0GBCIiIhIgwGBiIiINBgQiIiISIMBgYiIiDQYEIiIiEjDpq123KNHD+Xj49NWuyci\napcSExMvKKU82roO6vjaLCD4+PggISGhrXZPRNQuicjptq6BOgdeYiAiIiINBgQiIiLSYEAgIiIi\njTa7B4GIiCwjMTHxNhsbm9UAgsAvfmS+SgDJ5eXl0aGhoXk1VzIgEBG1czY2Nqt79uwZ4OHhUWBl\nZaXauh5qHyorK+X8+fP6nJyc1QAm1FzPpElE1P4FeXh4XGY4oMawsrJSHh4ehag686Rd38r1EBGR\n5VkxHFBTGP7e1JoFGBCIiIhIo9PfgxD8UXC965OeSGqlSoiILMNn0Y5QS27v1Fv3J5ozLi4urtsT\nTzzR/9ChQykhISFXLVlDayguLpbRo0fr/vvf/2acOHHCbteuXc4zZ8682NjthISE+B8+fDi9vjET\nJ07st2DBgtzQ0NBGH6ezZ8/aTJw40XfPnj3HG/vZxmjXAcFn0Y5615966/5WqqTtWeJYMCwRUXN8\n9tlnbkOHDi1ev369W0hIyNmW2k95eTlsbCz/42vp0qU9JkyYUGBjY4Pjx4/bb9y40a22gHD9+nXY\n2trWuZ2GwgEAbNy4sckzYvbu3bvc09Pz+vfff9/l3nvvvdLU7TSElxiIiKjZCgsLrRISEpzXrl17\n6ssvv+xuuu6vf/2rp06n0/v5+elnz57tBQDJycn2w4cP1/n5+en1en1ASkqK/fbt211Gjx49wPi5\nadOmecfGxroDgJeXV/ALL7zQKzQ01G/NmjXd33///R5BQUEBfn5++t/97nf9i4qKrAAgKyvLZuzY\nsf39/Pz0fn5++p07d3aZO3du7zfeeOM243afeeYZr7/97W+3oYb4+Hj3Rx999BIA/OUvf/FKSEhw\n9vf317/22mu3xcbGuo8bN+72//mf/xkwatQoXWFhoVVERIROr9cH6HQ6/ccff9zNuB0nJ6cQANi+\nfbtLeHi4X2Rk5O2+vr6BEyZM8K2srAQAhIeH+/34449OxvHPPPOMl5+fn37w4MH+WVlZNgCQkpJi\nP3jwYP+goKCAefPm9TZuFwAeeuihS3Fxce7N/oOrBwMCERE124YNG7rdc889hYMGDSrr1q1bxU8/\n/eQEAPHx8V137NjRPTExMT0jIyN18eLFOQAwZcoU35kzZ+ZlZGSkJiQkpHt7e19vaB8ODg6ViYmJ\nGTNmzCiYOnVqQXJyclpGRkaqn59faWxsbA8AmDlzpveoUaOKMjIyUlNSUlKHDh16dfbs2Rc+/fRT\ndwCoqKjAli1bukdHR+ebbvvq1auSlZVl7+fndw0A3nzzzd/CwsKK09PTUxcvXpwHAIcOHXL+9NNP\nf92/f/8xJyenyh07dmSmpqam7d69+9hLL73Ux/jD31RaWprjBx98kJWZmZly5swZ+507dzrXHFNa\nWmoVERFRnJGRkRoREVG8dOlSDwCYM2dO39mzZ+clJyen9e7d+6bjM2LEiCsHDhzQbMuSGBCIiKjZ\n4uPj3SZPnlwAAFFRURfXr1/vBgA7d+7s+thjj11wcXGpBABPT8+KgoICq9zcXLtp06ZdAgAnJydl\nXF+fadOmFRhfJyYmOoaGhvrpdDr95s2b3VNSUhwAYN++fS4vvvjieQCwsbGBu7t7hZ+f37Vu3bqV\n79271/HLL7/sGhgYWNKzZ88K023n5OTYuLi4lNe3/1GjRl329PSsAKrmEJg3b14fnU6nHz16tC4v\nL88uOztbc90jODj4Sv/+/a9bW1sjMDCw5MSJE3Y1x9ja2qpJkyYVAkBoaOiV06dP2wHA4cOHnf/4\nxz9eBICagaZ3797leXl5mm1ZUru+B4GIiNpeTk6O9f79+7seO3bMcc6cOaioqBARUStWrMhWSkFE\nbhqvVO1PZNra2irTb+FlZWU3fdA0RMyYMcN306ZNmREREaWxsbHuu3fvdqmvxieffPLC6tWre+Tl\n5dk++eST+TXXd+nSpfLatWv1fml2cnKq3v/KlSvd8vPzbZKSktLs7e2Vl5dXcGlpqebz9vb21b9Z\na2trlJeXS80xNjY2ysrKyvi61jE1lZSUiL29fYOhqjl4BoGI6hT8UXCDv4jWr1/f/eGHH84/e/Zs\n0m+//ZaUk5NztE+fPte+//5758jIyMvr16/vYbxHIDc319rNza2yZ8+e19avX98NAEpLS6WoqMiq\nf//+ZZmZmY6lpaWSn59v/dNPP3Wta58lJSVW3t7e18vKyuSzzz5zMy4fMWJE0bvvvusBVN3MePHi\nRSsAePzxxy/t2rXL9ciRI12ioqIKa27Pw8OjoqKiQkpKSgQAXF1dK4qLi63r2n9hYaF1jx49rtvb\n26tt27a5nD171uLf5ocMGVK8bt267gCwZs0aN9N1ycnJDjqdrtTS+zTFMwhEHRif9LmhMx0Lcx9L\ntJTPP//cfcGCBedMlz344IMF69evd9uwYcOZQ4cOOQ0ZMiTA1tZWjRkzpnDZsmW/ffzxx7/GxMT0\ne+ONN3rb2tqqzz///IRer782fvz4goCAgEBfX9+rgYGBJXXtc9GiRWfDw8MDvLy8rgUEBJQYf5iv\nWLHizPTp0/vpdLoeVlZWWLZs2ekxY8ZccXBwUMOHD7/crVu3irqegLjrrrsKv//+e+eHHnqoKDw8\nvNTGxkb5+fnpp0yZcqF79+43XZKIjo6+OG7cuAFBQUEBgYGBJb6+vhZ/rHPp0qVZU6dO9Y2Nje15\n7733XnJ2dq6uYefOnS6RkZGaoGNJUtepnpYWFhamEhISmrUNPtp3A48F1aa5fy/MOUPQXv5edJRj\nISKJSqkw02VHjhw5NXjw4AstvvN2rKKiAoGBgfrPP//8RHBwcFltY/bu3ev47rvv9tyyZcuvrV1f\nbYqKiqy6dOlSaWVlhVWrVnXfuHGj2w8//HACAMLCwvy++eabTA8Pj4qGttOQI0eO9Bg8eLBPzeU8\ng0BERB1aYmKiw4MPPjhw3LhxBXWFAwAYMWJE6cGDBy+31DwLjbV3716nuXPneiul0LVr14p169ad\nAqomSpo7d26uJcJBfdr+CBAREbWg0NDQq9nZ2Wad3pk3b57mBsa2EhkZWZyRkZFac3nv3r3LH3/8\n8UstvX/epEhEREQaDAhERESkwUsMRDXcKjejERG1JQYE6nA60+NsRNR5Xb582WrFihXuL7zwwnlr\n6zqnbGgyBgQioo7mVVeLtnvGq4Wdrt1zY59iyMjIsHvggQcGHj9+POXHH390WrNmjfu6deuyao7z\n8vIKTkhISOvVq1e90zrXtGHDBteUlBTHJUuW5ABVHSX/+Mc/ei9YsCC3oXDQ1PbQDAhERGQRHand\nc3PcddddJXfddVedkzw1xdSpUwsBVE+MZGtri02bNp0y57NNbQ/NmxSJiKjZOlq75/vvv//2jRs3\nuhrXRUVF+axbt65bRkaGXWhoqJ9erw/Q6/UBO3fu7FJzO6a/j5ycHOsRI0YMDAgI0E+ZMqWf6eSE\nY8aM6R8YGBgwYMCAwPfee6+HcfmmTZu66vX6AD8/P31ERIQOAGJjY92nTZvmDQDHjh2zi4iI0Ol0\nOn1ERITu+PHjdsYap0+f3jckJMS/T58+wWvXrq3+c2hKe2gGBCIiaraO1u554sSJFzdu3NjduG7v\n3r1dH3nkkcLevXuX79mz51hqamraxo0bTz733HPe9dW8aNGi3hEREcVpaWmpEyZMuHTu3Lnqng0b\nNmw4lZKSkvbLL7+krly50jMnJ8f67NmzNnPmzPH54osvTmRkZKRu2bLlRM1tzpw503vKlCn5x44d\nS504cWL+rFmz+hrX5ebm2iYkJKR/9dVXxxcvXuxlXN6U9tC8xEBERM0WHx/vNnfu3DzgRrvnkSNH\nlpjb7hlAg/P+12z3/Morr3gVFRVZX7lyxfruu+8uBKraPW/atOlX4Ea7Z3d39wpju+dz587ZmtPu\n+ZFHHilcsGCBd2lpqWzevNk1PDy8yNnZWeXn51s99dRT/VJTUx2trKxw+vRp+/pq3r9/v8sXX3yR\nCQCTJk0qfPrpp6v3+/bbb3vu2LGjm2H/tikpKQ65ubk24eHhRf7+/teMx6vmNg8fPtzlm2++OQEA\ns2bNuvjaa6/1Ma6bMGHCJWtra4SGhl7Nz8+3NS5vSntoBgQiImqWjtju2cnJSQ0bNqzoiy++6Lpx\n48bukydPvggAb775pudtt912ffPmzb9WVlbC0dGxwRtCja2cTW3fvt1l9+7dLgkJCekuLi6V4eHh\nfqWlpVa1Ha/GcHBwqD64pse5Ke2hzbrEICKRIpIhIpkisqiW9d4isktEDovIURG5rzFFEBFR+9UR\n2z0DwKRJky6uW7eux8GDB10efvjhy0BVm+devXpdt7a2xvLly90rKupvhzBs2LCiNWvWuANVl1su\nX75sDQCXLl2ydnV1rXBxcak8fPiww5EjR7oAwOjRo6/8/PPPLunp6XbG41VzmyEhIVdWr17dHQBW\nrlzpFhYWVlxvEWhae+gGzyCIiDWADwCMBZAN4KCIbFVKmc4P/VcA8UqpFSKiB/A1AJ/GFEJERBZi\n5mOJltIR2z0DwO9///vLM2fO9B0zZswl4zfzefPm5UVFRfXfsmVL95EjRxY5OjrW+638rbfeOhsV\nFXW7Xq8PiIiIKO7Vq9c1AIiKiipctWqVh06n0/fv3//q4MGDrwBVlwJiY2NP/f73vx9QWVkJd3f3\n6/v27bvp8cQVK1aceeKJJ3z+7//+r6e7u3t5XFzcqYb+jJrSHrrBds8iEgHgVaXU7wzv/wwASqm/\nm4xZCeCkUuptw/j3lVLD69su2z1bFo/FDR2lra8l8Fjc0FGOBds9N017bPdsSfW1h66r3bM5lxi8\nAJhO9pBtWGbqVQCPiUg2qs4ePFPbhkRkhogkiEjC+fPnzdg1ERFR8yQmJjr069cveNSoUZcbavd8\nzz33XC4vb9QcRre8praHNucmxdrulqh52mEygHVKqfcNZxDWi0iQUuqmUy9KqVUAVgFVZxAaUygR\nEVFTtNd2z5bS1PbQ5pxByAbQ1+R9HwA1Z8h6CkA8ACil/gvAAUAPEBERUbtkTkA4CGCgiPiKiB2A\nSQC21hhzBsD/AoCIBKAqIPAaAhERUTvV4CUGpVS5iMwB8B0AawBrlFIpIvI6gASl1FYAzwP4UESe\nQ9Xlh+mqobsfiYhuJa+61r/et94J8wAAaf4B9a4PSE9rTEVEbcqsiZKUUl+j6uZD02WvmLxOBTDC\nsqURERFRW+FMikREHUzwR8EWbfec9ERSk9s9b9++3eX999/33LVrV6ZxXFRUlM8DDzxQ+OSTTxaU\nlZXJc88913vHjh3d7ezslIODQ+XLL7/826OPPnrZdNvh4eF+eXl5tvb29pW2trZq1apVp4YPH14K\nAPn5+dbR0dF9ExISnAEgLCysePXq1Vnu7u4VAHD06FH7Z555pu+vv/7qYGNjo/z9/UtXrlx5pm/f\nvjc9rnD69Gnb6dOn99u1a1fmvn37HLOysuwmTpzYqLkDTp06ZTtz5sy+33777cn6xt19990DNm/e\n/GuPHj0a9WQBABw4cMDx7bff9ty8efOpxn62MdisiYiILMK03bO5n3nuued65+Tk2Kanp6ccP348\n5euvvz5unG2wpri4uJMZGRmpMTExeS+88EJ1/4GpU6f28/X1vZaVlZWclZWV7OPjc+2xxx7rB1RN\nMTx+/PiBTz/99PkzZ84knzx5MmXWrFnnc3JyNF+QlyxZ4vnUU09dAICEhASnHTt21Hrd6fr1uvtK\n+fj4XG8oHADA7t27M5sSDgAgPDy89Ny5c3bGLo4thQGBiIiarb52z3UpKiqy+uSTTzxWr159xtHR\nUQFA3759y6Ojowvq+9xdd911JTc31w6oahudlJTU5Z133ql+uu7dd989e/To0S4pKSn2q1atchs6\ndGjxlClTqs8EjB8/vuiOO+64WnO7O3bs6B4VFVV49epV+fvf/95727Zt3f39/fUffvhh9/nz5/ee\nPHlyvxEjRgx8+OGHfetq+5yRkWE3cODAQKCqRfO9997bf9SoUQP79esXNHPmzOpQ4+XlFXzu3Dmb\njIwMu9tvvz1w0qRJ/QYMGBA4YsSIgcXFxQIAu3fvdtLpdPohQ4b4P/30032M2wWAcePGXfroo4/M\nOs5NxUsMRJ0Zb8wjC6mt3fPIkSPrnCoZAFJTU+179ep1zc3NrVFNhLZt29Z13LhxlwDgyJEjDnq9\nvsR0+mQbGxvo9fqSX375xSE5Odlx6NCh9dYBAOnp6Xaurq7lxqDy5z//+WxCQkKXuLi4MwAwf/58\nx6NHjzr9/PPP6c7OzqqoqMhqz549x5ycnFRSUpL95MmTb09OTtb8ZU9NTXU6cuRIqqOjY+WAAQOC\nXnjhhdwBAwbcdArizJkzDh9//PHJ4cOHn77vvvtuj4uL6z579uyL0dHRvsuXLz81duzYK7Nnz75p\ngsI777zzyltvvdULQG5jjl1jMCAQEVGz1dXuWURqfaKtruX1mTZt2u2lpaVWlZWVSEhISAMApZTU\n1v2wsV0Rs7KybN3c3OqdQjEyMvKSs7OzAoBr166JOW2fR44cedl4L8SAAQOunjhxwr5mQPDy8ioz\n3k8REhJScurUKfsLFy5YX7lyxWrs2LFXAOCJJ564uHPnzm7Gz/Tq1as8NzfXFi2IlxiIiKhZjO2e\n//SnP/Xz8vIKXrZsWc+tW7d2r6ysxG233VZeWFh405fRgoICGw8Pj3K9Xl927tw5u4KCArN+FsXF\nxZ08c+ZM0kMPPXQxJibGGwCGDBlSmpKS4mTaVbGiogJpaWlOgwYNuhoYGHj10KFDTg1t28nJqbKs\nrKzeOrp06VJ9psPY9jktLS01KSkp9fr167V+1s7OrjoIWVtbq+vXr2tSS80x5eXlDfZJKi0ttXJw\ncGjUmZfGYkAgIqJmqa/dc1BQUFlubq7toUOHHADg2LFjdunp6Y7Dhg0rdXFxqZw0adKFmJgY76tX\nrwpQ9STB8uXL67zJ0d7eXv3jH//47Zdffuly6NAhh6CgoLLAwMCShQsX9jKOWbhwYa+goKCSoKCg\nspiYmPzExETnzz77rPp62qZNm7oeOHDA0XS7wcHBZb/99lv1TX9du3atKC4urvNnZGPbPjeWh4dH\nRZcuXSp/+OGHLgBQ88bP1NRUez8/v0a1b24sXmIgIupgzH0s0VLqa/ccGRlZvHbt2pNPPvmkT1lZ\nmZWNjY364IMPThtPu//zn//8bd68eV46nS7Q3t5eOTo6VixevLjmdP43cXZ2VrNmzcp96623POPj\n409v2LDhVHR0tLe3t3eQUgpDhw69smHDhlPGsV999VXms88+23fhwoV9bWxsVEBAQOmKFSvOmG6z\na9euld7e3mXJycn2QUFBZePGjSt67733evn7++uff/75czVraGzb56ZYuXLlqZkzZ/ZzcnKqHDFi\nRJGLi0t1Cvn3v//d9YEHHmjUI5iN1eBpjJbCds+WxWNxQ0dp62sJDR4Lhyn1rg824ybF+L/X3/nu\nVrlJsaMcC7Z7bjlxcXHdEhISnGJjY+sNKK2lsLDQytXVtRIAXnrppZ7nzp2zXbt2bVZpaakMGzbM\nLyEhId3Wtvm3IdTV7plnEIiIiABMmzbt0oULF26Zn4vx8fGu77//fq+Kigrx8vIq++STT04BQGZm\npt2bb775myXCQX1umQNBRETU1ubPn3/LnImJiYkpiImJ0cwJERwcXBYcHFzW0vvnTYpERESkwYBA\nREREGgwIREREpMGAQERE1A5lZWXZLF261L2lts+bFImIOpg0/wCLtnsOSE/rdO2eG3uMTH+fGzZs\ncE1JSXFcsmRJTs1xTk5OISUlJYcbu/133nnHw8nJqXLOnDn5AFBQUGA1a9Ys73/+859ZDX22qe2h\neQaBiIgsoiO1e26OqVOnFtYWDppjwYIF543hAAC6d+9euX379pM1+zrUpqntoRkQiIio2TpSu2cA\nGDRokH9CQoKDcV14eLjfnj17nHbt2uUUEhLiHxAQoA8JCfE/cuSIpklTbGys+7Rp07yBqi6RQ4YM\n8Q8KCgqYO3dub9PjFRERodPr9QE6nU7/8ccfVzdiWrZsmbtOp9P7+fnpH3roIV8AmD9/fu9XXnnF\nEwD27dvnOHjwYH+dTqcfO3Zs//Pnz1sba5w1a5ZXcHBwgI+PT9C3337rbNxmU9pDMyAQEVGz1dbu\nuaHP3MrtnqOioi5u2LDBDai69JCXl2c7atSoksGDB189cOBAelpaWurixYt/W7BgQZ/6tjt79mzv\n6Ojo88nJyWk9e/as/rbv5ORUuWPHjszU1NS03bt3H3vppZf6GLpUOrz33nu9du/efSwjIyN15cqV\nZ2puc/r06b5LlizJPnbsWGpgYGDpwoULq4NHeXm5JCUlpb399ttZr7/+evXyO++888q+fftcGjoO\nphgQiIio2eLj490mT55cANxo9wzU3da5qe2ePT09By1durTniy++mAe0XLvnadOmFWzdurU7AMTF\nxXUfP358AQBcvHjR+r777us/cODAwAULFvQ9duyYQ13bBIBDhw45x8TEXASAp59+uvoSQWVlpcyb\nN6+PTqfTjx49WpeXl2eXnZ1t891333UdP358Qa9evcoBwNPT86YuUPn5+dZFRUXW999/fzEAxMTE\n5O/fv7/6TMEf/vCHAgAYPnz4lezs7OpLCk1pD82AQEREzdIR2z37+vpe79atW/nPP//s+MUXX7g9\n/vjjFwFg4cKFXnfffXfR8ePHU7Zt25Z57dq1Bmu3srLShKGVK1e65efn2yQlJaWlp6enuru7Xy8t\nLbUyBJsmN0lycHBQQNVZlIqKiuqE1JT20B07ILzq2vCvzoLHgohaSEds9wwAjzzyyMUlS5b0LCoq\nsg4PDy8FgMuXL1v36dPnGgCsXLmyR0PHZujQocUffvihGwB8+OGH1Y8kFhYWWvfo0eO6vb292rZt\nm8vZs2ftACAyMvLy1q1b3XJycqwBIDc396YbNt3d3Su6du1aYby/4F//+pd7REREcUN1NKU9NB9z\nbECaf0C962+VTnVEREbmPpZoKR2x3TMAPPbYYwUvv/yy99y5c6vrWbhwYU50dLRvbGxsz1GjRt30\nKGZtli9ffmbSpEm3L1++3HPChAnVN19GR0dfHDdu3ICgoKCAwMDAEl9f36sAEBYWdvX5558/N2rU\nKH8rKysVFBRUUvPxxLVr1/46a9asfs8++6yVt7d32aeffnrT+to0pT10x2733ED7VqDhFq6dpZUt\n0PCx6DAtjtnuuVp7aXFsCR3lWLDdc8u51do9W0pD7aHZ7pmIiKget1q7Z0tpanvoDncgiIiImupW\navdsKU1tD92xb1IkIuocKisrK81/po/IwPD3ptanGxgQiIjav+Tz58+7MiRQY1RWVsr58+ddASTX\ntp6XGIiI2rny8vLonJyc1Tk5OUHgFz8yXyWA5PLy8ujaVjIgkNn4yCfRrSk0NDQPwIS2roM6FiZN\nIiIi0mBAICIiIg0GBCIiItJgQCAiIiINBgQiIiLSYEAgIiIiDbMCgohEikiGiGSKyKI6xjwqIqki\nkiIin1i2TCIiImpNDc6DICLWAD4AMBZANoCDIrJVKZVqMmYggD8DGKGUKhCR21qqYCIiImp55pxB\nCAeQqZQ6qZS6BuAzAA/WGBMD4AOlVAEAKKXyLFsmERERtSZzAoIXgCyT99mGZaZ0AHQisldE9otI\npKUKJCIiotZnzlTLtTX/ULVsZyCAewD0AbBHRIKUUpdu2pDIDAAzAMDb27vRxRIREVHrMOcMQjaA\nvibv+wA4W8uYr5RS15VSvwLIQFVguIlSapVSKkwpFebh4dHUmomIiKiFmRMQDgIYKCK+ImIHYBKA\nrTXGbAEwGgBEpAeqLjmctGShRERE1HoaDAhKqXIAcwB8ByANQLxSKkVEXhcRY/ew7wDki0gqgF0A\nXlRK5bdU0URERNSyzGr3rJT6GsDXNZa9YvJaAZhv+EVERETtHGdSJCIiIg0GBCIiItIw6xIDEd0s\nzT+g3vUB6WmtVAkRUcvgGQQiIiLS4BkE6nxeda1/vS8n8SIi4hkEIiIi0mBAICIiIg0GBCIiItJg\nQCAiIiINBgQiIiLSYEAgIiIiDQYEIiIi0mBAICIiIg0GBCIiItJgQCAiIiINBgQiIiLSYEAgIiIi\nDQYEIiIi0mBAICIiIg0GBCIiItJgQCAiIiINBgQiIiLSYEAgIiIiDQYEIiIi0mBAICIiIg0GBCIi\nItJgQCAiIiINBgQiIiLSYEAgIiIiDQYEIiIi0mBAICIiIg0GBCIiItJgQCAiIiINBgQiIiLSYEAg\nIiIiDQYEIiIi0mBAICIiIg2zAoKIRIpIhohkisiiesY9IiJKRMIsVyIRERG1tgYDgohYA/gAwDgA\negCTRURfyzgXAM8C+NnSRRIREVHrMucMQjiATKXUSaXUNQCfAXiwlnFvAHgHwFUL1kdERERtwJyA\n4AUgy+R9tmFZNREJAdBXKbXdgrURERFRGzEnIEgty1T1ShErAP8A8HyDGxKZISIJIpJw/vx586sk\nIiKiVmVOQMgG0NfkfR8AZ03euwAIAvAfETkFYBiArbXdqKiUWqWUClNKhXl4eDS9aiIiImpR5gSE\ngwAGioiviNgBmARgq3GlUqpQKdVDKeWjlPIBsB/ABKVUQotUTERERC2uwYCglCoHMAfAdwDSAMQr\npVJE5HURmdDSBRIREVHrszG5XST4AAAKAklEQVRnkFLqawBf11j2Sh1j72l+WURERNSWOJMiERER\naTAgEBERkQYDAhEREWkwIBAREZEGAwIRERFpMCAQERGRBgMCERERaTAgEBERkQYDAhEREWkwIBAR\nEZEGAwIRERFpMCAQERGRBgMCERERaTAgEBERkQYDAhEREWkwIBAREZEGAwIRERFpMCAQERGRBgMC\nERERaTAgEBERkQYDAhEREWkwIBAREZEGAwIRERFpMCAQERGRBgMCERERaTAgEBERkQYDAhEREWkw\nIBAREZEGAwIRERFpMCAQERGRBgMCERERaTAgEBERkQYDAhEREWkwIBAREZEGAwIRERFpMCAQERGR\nBgMCERERaZgVEEQkUkQyRCRTRBbVsn6+iKSKyFER+UFE+lm+VCIiImotDQYEEbEG8AGAcQD0ACaL\niL7GsMMAwpRSgwBsAvCOpQslIiKi1mPOGYRwAJlKqZNKqWsAPgPwoOkApdQupVSJ4e1+AH0sWyYR\nERG1JnMCgheALJP32YZldXkKwDfNKYqIiIjalo0ZY6SWZarWgSKPAQgDcHcd62cAmAEA3t7eZpZI\nRERErc2cMwjZAPqavO8D4GzNQSIyBsBfAExQSpXVtiGl1CqlVJhSKszDw6Mp9RIREVErMCcgHAQw\nUER8RcQOwCQAW00HiEgIgJWoCgd5li+TiIiIWlODAUEpVQ5gDoDvAKQBiFdKpYjI6yIywTDsXQDO\nAD4XkV9EZGsdmyMiIqJ2wJx7EKCU+hrA1zWWvWLyeoyF6yIiIqI2xJkUiYiISIMBgYiIiDQYEIiI\niEiDAYGIiIg0GBCIiIhIgwGBiIiINBgQiIiISIMBgYiIiDQYEIiIiEiDAYGIiIg0GBCIiIhIgwGB\niIiINBgQiIiISIMBgYiIiDQYEIiIiEiDAYGIiIg0GBCIiIhIgwGBiIiINBgQiIiISIMBgYiIiDQY\nEIiIiEiDAYGIiIg0GBCIiIhIgwGBiIiINBgQiIiISIMBgYiIiDQYEIiIiEiDAYGIiIg0GBCIiIhI\ngwGBiIiINBgQiIiISIMBgYiIiDQYEIiIiEiDAYGIiIg0GBCIiIhIgwGBiIiINBgQiIiISMOsgCAi\nkSKSISKZIrKolvX2IrLRsP5nEfGxdKFERETUehoMCCJiDeADAOMA6AFMFhF9jWFPAShQSg0A8A8A\nb1u6UCIiImo95pxBCAeQqZQ6qZS6BuAzAA/WGPMggI8MrzcB+F8REcuVSURERK3JxowxXgCyTN5n\nA7izrjFKqXIRKQTgDuCC6SARmQFghuFtsYhkNKVoc5mXUJJ7oEadpmqeKtHupH3kIB6LGxqusv7j\nAPBYmOKxuKGVjkU/S2yEqCHmBITa/karJoyBUmoVgFVm7LPViEiCUiqsreu4FfBYVOFxuIHH4gYe\nC+pszLnEkA2gr8n7PgDO1jVGRGwAuAK4aIkCiYiIqPWZExAOAhgoIr4iYgdgEoCtNcZsBfCE4fUj\nAP6tlNKcQSAiIqL2ocFLDIZ7CuYA+A6ANYA1SqkUEXkdQIJSaiuAfwFYLyKZqDpzMKkli7awW+qS\nRxvjsajC43ADj8UNPBbUqQi/6BMREVFNnEmRiIiINBgQiIiISIMBgYiIiDQYEKjTE5FwEbnD8Fov\nIvNF5L62rutWICJxbV0DEbUNcyZKog5IRPxRNQPmz0qpYpPlkUqpb9uustYlIotR1WfERkR2omqW\n0P8AWCQiIUqpN9uyvtYkIjUfXxYAo0WkGwAopSa0flW3BhEZiapp55OVUt+3dT1ErYFPMRiIyJNK\nqbVtXUdrEJFnAfwJQBqAIQDmKqW+Mqw7pJQa2pb1tSYRSULVMbAHkAOgj1Lqsog4oio8DWrTAluR\niBwCkApgNapmQhUAn8Lw2LJSanfbVde6ROSAUirc8DoGVf9evgRwL4BtSqm32rI+otbASww3vNbW\nBbSiGAChSqmHANwD4GURmWtY1z4mzreccqVUhVKqBMAJpdRlAFBKlQKobNvSWl0YgEQAfwFQqJT6\nD4BSpdTuzhQODGxNXs8AMFYp9RqqAsLUtimJqHV1qksMInK0rlUAPFuzljZmbbysoJQ6JSL3ANgk\nIv3Q+QLCNRFxMgSEUONCEXFFJwsISqlKAP8Qkc8N/81FJ/t/hAkrEemOqi9RopQ6DwBKqSsiUt62\npRG1js72j98TwO8AFNRYLgD2tX45bSZHRIYopX4BAKVUsYg8AGANgOC2La3V3aWUKgOqf0Aa2eLG\n9OGdilIqG8AfROR+AJfbup424oqqsykCQIlIT6VUjog4o/OFaOqkOtU9CCLyLwBrlVI/1bLuE6XU\nlDYoq9WJSB9UnVrPqWXdCKXU3jYoi+iWJyJOADyVUr+2dS1ELa1TBQQiIiIyD29SJCIiIg0GBKJW\nIiLWIvInEXFo61qIiBrCgEC3LBGpEJFfRCRZRD43XP9tzf3Pa+o+RSRMRGJrLH4PQJpS6mrzqyMi\nalm8B4FuWSJSrJRyNrzeACBRKfX/zPystVKqopn7PwUgTCl1oTnbISJqj3gGgdqLPQAGAICIPCYi\nBwxnF1aKiLVhebGIvC4iPwOIEJFTIrJERP4rIgkiMlREvhOREyIy0/CZe0Rku3EnIrJMRKYbZpvs\nDWCXiOwyrFth2E6KiLxm8pk7RGSfiBwx1OViul0RcRORLSJyVET2i8ggw/JXRWSNiPxHRE4a9klE\ndEtgQKBbnojYoKpfQpKIBACYCGCEUmoIgArcmNmuC6rmyr/T5FHWLKVUBKoCxjoAjwAYBuD1+vap\nlIoFcBbAaKXUaMPivyilwgAMAnC3iAwSETsAG1E1XfVgAGMAlNbY3GsADhumbX4JgGkDJH9Uzc0R\nDmCxiNiCiOgW0NkmSqL2xVFEfjG83gPgX6ia9jYUwEERAQBHAHmGMRUANtfYhrEBURIAZ6VUEYAi\nEblqbELUCI+KyAxU/bvpBUCPqp4F55RSBwHAOFWzoTajkQCiDOv/LSLuhpkaAWCHYaKmMhHJQ9Vk\nXtmNrIuIyOIYEOhWVmo4S1BNqn7yfqSU+nMt46/Wct9BmeG/lSavje9tAJTj5jNptT5hICK+AF4A\ncIdSqkBE1hnGCqpCQn1qm3nP+BnTmirAf5NEdIvgJQZqb34A8IiI3AZUX9/v14ztnQagFxF7w7f6\n/zVZVwTAxfC6K4ArAApFxBNVlzwAIB1AbxG5w1CPi+GSiKkfYbgMYuh7ccF4poGI6FbFbyvUriil\nUkXkrwC+FxErANdR1Yr3dBO3lyUi8QCOAjgO4LDJ6lUAvhGRc0qp0SJyGEAKgJMA9ho+f01EJgJY\namgRXYqq+xBMvQpgraFZWAk6aY8HImpf+JgjERERafASAxEREWkwIBAREZEGAwIRERFpMCAQERGR\nBgMCERERaTAgEBERkQYDAhEREWn8f0tMPYnjn/oTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb09a6943c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "accuracies_training = []\n",
    "accuracies_validation = []\n",
    "aucs_training = []\n",
    "aucs_validation = []\n",
    "\n",
    "# Puede serles de utilidad tener a X_dev e y_dev como matrices de numpy directamente:\n",
    "X_dev_np = np.array(X_dev)\n",
    "y_dev_np = np.array(y_dev).ravel()\n",
    "\n",
    "########################################################\n",
    "## AQUI VA SU CODIGO \n",
    "## Objetivo: accuracies_training, accuracies_validation, aucs_training y aucs_validation asignados\n",
    "\n",
    "\n",
    "#kf = KFold(n_splits=5, random_state=1234, shuffle=True)\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "for train_index, test_index in kf.split(X_dev):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X_dev_np[train_index], X_dev_np[test_index]\n",
    "    y_train, y_test = y_dev_np[train_index], y_dev_np[test_index]\n",
    "    \n",
    "    arbol = DecisionTreeClassifier(max_depth=3)\n",
    "    arbol.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_test = arbol.predict(X_test)\n",
    "    y_pred_train = arbol.predict(X_train)\n",
    "    \n",
    "    ac_test=sklearn.metrics.accuracy_score(y_test, y_pred_test, normalize=True, sample_weight=None)\n",
    "    ac_train=sklearn.metrics.accuracy_score(y_train, y_pred_train, normalize=True, sample_weight=None)\n",
    "    accuracies_validation.append(ac_test)\n",
    "    accuracies_training.append(ac_train)\n",
    "    \n",
    "    roc_auc_test=sklearn.metrics.roc_auc_score(y_test, y_pred_test, sample_weight=None)\n",
    "    roc_auc_train=sklearn.metrics.roc_auc_score(y_train, y_pred_train, sample_weight=None)\n",
    "    aucs_training.append(roc_auc_train)\n",
    "    aucs_validation.append(roc_auc_test)\n",
    "\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(1,6))\n",
    "df.index.name = \"Permutación\"\n",
    "                  \n",
    "df[\"Accuracy (training)\"] = accuracies_training     # cambiar por accuracies_training\n",
    "df[\"Accuracy (validación)\"] = accuracies_validation   # cambiar por accuracies_validation\n",
    "df[\"AUC ROC (training)\"] = aucs_training     # cambiar por aucs_training\n",
    "df[\"AUC ROC (validación)\"] = aucs_validation    # [\"-\"] * 5 cambiar por aucs_validation\n",
    "\n",
    "\n",
    "display(HTML(\"<h3> TABLA 1 </h3>\"))\n",
    "display(df)\n",
    "\n",
    "# Descomentar las siguientes líneas para graficar el resultado\n",
    "df.plot(kind=\"bar\")\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 2 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altura máxima</th>\n",
       "      <th>Criterio de evaluación de corte</th>\n",
       "      <th>AUC ROC promedio (training)</th>\n",
       "      <th>AUC ROC promedio (validación)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.8861</td>\n",
       "      <td>0.7013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.9888</td>\n",
       "      <td>0.6818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Gini</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.8794</td>\n",
       "      <td>0.7391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.7160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Altura máxima Criterio de evaluación de corte  AUC ROC promedio (training)  \\\n",
       "0             3                            Gini                       0.8861   \n",
       "1             5                            Gini                       0.9888   \n",
       "2     Inifinito                            Gini                       1.0000   \n",
       "3             3         Ganancia de Información                       0.8794   \n",
       "4             5         Ganancia de Información                       0.9824   \n",
       "5     Inifinito         Ganancia de Información                       1.0000   \n",
       "\n",
       "   AUC ROC promedio (validación)  \n",
       "0                         0.7013  \n",
       "1                         0.6818  \n",
       "2                         0.6849  \n",
       "3                         0.7391  \n",
       "4                         0.7160  \n",
       "5                         0.7163  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultados_training = []\n",
    "resultados_validation = []\n",
    "\n",
    "########################################################\n",
    "## AQUI VA SU CODIGO \n",
    "## Objetivo: resultados_training y resultados_validation asignadas\n",
    "#\n",
    "## Recomendamos seguir el siguiente esquema:\n",
    "np.random.seed(SEED)\n",
    "for criterio in [\"gini\", \"entropy\"]:\n",
    "     for altura in [3, 5, None]:\n",
    "        \n",
    "        lista_aucs_train = []\n",
    "        lista_aucs_test = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(X_dev):\n",
    "            #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            X_train, X_test = X_dev_np[train_index], X_dev_np[test_index]\n",
    "            y_train, y_test = y_dev_np[train_index], y_dev_np[test_index]\n",
    "\n",
    "            arbol = DecisionTreeClassifier(max_depth=altura, criterion=criterio)\n",
    "            arbol.fit(X_train, y_train)\n",
    "\n",
    "            y_pred_test = arbol.predict(X_test)\n",
    "            y_pred_train = arbol.predict(X_train)\n",
    "\n",
    "            #ac_test=sklearn.metrics.accuracy_score(y_test, y_pred_test, normalize=True, sample_weight=None)\n",
    "            #ac_train=sklearn.metrics.accuracy_score(y_train, y_pred_train, normalize=True, sample_weight=None)\n",
    "            #accuracies_validation.append(ac_test)\n",
    "            #accuracies_training.append(ac_train)  \n",
    "            \n",
    "            #EN EL PDF DICE ACURACY, ACA FIGURA AUC ROC\n",
    "            \n",
    "            roc_auc_test=sklearn.metrics.roc_auc_score(y_test, y_pred_test, sample_weight=None)\n",
    "            roc_auc_train=sklearn.metrics.roc_auc_score(y_train, y_pred_train, sample_weight=None)\n",
    "            lista_aucs_train.append(roc_auc_train)\n",
    "            lista_aucs_test.append(roc_auc_test)\n",
    "                \n",
    "\n",
    "        resultados_training.append( np.mean(lista_aucs_train) )\n",
    "        resultados_validation.append( np.mean(lista_aucs_test) )\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(0,6))\n",
    "\n",
    "df[\"Altura máxima\"] = [3, 5, \"Inifinito\"] * 2\n",
    "df[\"Criterio de evaluación de corte\"] = [\"Gini\"] * 3 + [\"Ganancia de Información\"] * 3\n",
    "df[\"AUC ROC promedio (training)\"] = resultados_training # reemplazar por resultados_training\n",
    "df[\"AUC ROC promedio (validación)\"] = resultados_validation # reemplazar por resultados_validation\n",
    "\n",
    "   \n",
    "display(HTML(\"<h3> TABLA 2 </h3>\"))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from math import log\n",
    "\n",
    "def construir_arbol(instancias, etiquetas, criterion, max_depth):\n",
    "    # ALGORITMO RECURSIVO para construcción de un árbol de decisión binario. \n",
    "    \n",
    "    if max_depth == 0 or len(instancias) <= 2:\n",
    "        return Hoja(etiquetas)\n",
    "    \n",
    "    # Suponemos que estamos parados en la raiz del árbol y tenemos que decidir cómo construirlo. \n",
    "    ganancia, pregunta = encontrar_mejor_atributo_y_corte(instancias, etiquetas, criterion)\n",
    "    \n",
    "    # Criterio de corte: ¿Hay ganancia?\n",
    "    if ganancia == 0:\n",
    "        #  Si no hay ganancia en separar, no separamos. \n",
    "        return Hoja(etiquetas)\n",
    "    else: \n",
    "        # Si hay ganancia en partir el conjunto en 2\n",
    "        instancias_cumplen, etiquetas_cumplen, instancias_no_cumplen, etiquetas_no_cumplen = partir_segun(pregunta, instancias, etiquetas, criterion)\n",
    "        # partir devuelve instancias y etiquetas que caen en cada rama (izquierda y derecha)\n",
    "\n",
    "        new_max_depth = None\n",
    "        if max_depth != None:\n",
    "            new_max_depth = max_depth - 1\n",
    "            \n",
    "        # Paso recursivo (consultar con el computador más cercano)\n",
    "        sub_arbol_izquierdo = construir_arbol(instancias_cumplen, etiquetas_cumplen, criterion, new_max_depth)\n",
    "        sub_arbol_derecho   = construir_arbol(instancias_no_cumplen, etiquetas_no_cumplen, criterion, new_max_depth)\n",
    "        # los pasos anteriores crean todo lo que necesitemos de sub-árbol izquierdo y sub-árbol derecho\n",
    "        \n",
    "        # sólo falta conectarlos con un nodo de decisión:\n",
    "        return Nodo_De_Decision(pregunta, sub_arbol_izquierdo, sub_arbol_derecho)\n",
    "    \n",
    "    \n",
    "# Definición de la estructura del árbol. \n",
    "\n",
    "class Hoja:\n",
    "    #  Contiene las cuentas para cada clase (en forma de diccionario)\n",
    "    #  Por ejemplo, {'Si': 2, 'No': 2}\n",
    "    def __init__(self, etiquetas):\n",
    "        self.cuentas = dict(Counter(etiquetas))\n",
    "\n",
    "\n",
    "class Nodo_De_Decision:\n",
    "    # Un Nodo de Decisión contiene preguntas y una referencia al sub-árbol izquierdo y al sub-árbol derecho\n",
    "     \n",
    "    def __init__(self, pregunta, sub_arbol_izquierdo, sub_arbol_derecho):\n",
    "        self.pregunta = pregunta\n",
    "        self.sub_arbol_izquierdo = sub_arbol_izquierdo\n",
    "        self.sub_arbol_derecho = sub_arbol_derecho\n",
    "        \n",
    "        \n",
    "# Definición de la clase \"Pregunta\"\n",
    "class Pregunta:\n",
    "    def __init__(self, atributo, valor):\n",
    "        self.atributo = atributo\n",
    "        self.valor = valor\n",
    "    \n",
    "    def cumple(self, instancia):\n",
    "        # Devuelve verdadero si la instancia cumple con la pregunta\n",
    "        return instancia[self.atributo] == self.valor\n",
    "    \n",
    "    def __repr__(self):\n",
    "        try:\n",
    "            float(self.valor)\n",
    "            return \"¿Es el valor para {} <= a {}?\".format(self.atributo, self.valor)\n",
    "        except:\n",
    "            return \"¿Es el valor para {} igual a {}?\".format(self.atributo, self.valor)\n",
    "    \n",
    "def gini(etiquetas):\n",
    "    d = dict(Counter(etiquetas))\n",
    "    impureza = 1\n",
    "    for key, value in d.items():\n",
    "        impureza -= (value/len(etiquetas))**2\n",
    "    return impureza\n",
    "\n",
    "def ganancia_gini(instancias, etiquetas_rama_izquierda, etiquetas_rama_derecha):\n",
    "    # COMPLETAR\n",
    "    ganancia_previa = gini(etiquetas_rama_izquierda + etiquetas_rama_derecha)\n",
    "    gini_izq = gini(etiquetas_rama_izquierda)\n",
    "    \n",
    "    proporcion_izq = (len(etiquetas_rama_izquierda)/len(instancias))\n",
    "    proporcion_der = (len(etiquetas_rama_derecha)/len(instancias))\n",
    "    \n",
    "    gini_der = gini(etiquetas_rama_derecha)\n",
    "    ganancia_gini = ganancia_previa - ((gini_izq*proporcion_izq + gini_der*proporcion_der)/2)\n",
    "    return ganancia_gini\n",
    "\n",
    "def entropy(etiquetas):\n",
    "    d = dict(Counter(etiquetas))\n",
    "    entropy = 0\n",
    "    for key, value in d.items():\n",
    "        proportion = value/len(etiquetas)\n",
    "        entropy -= (proportion)*log(proportion, 2)\n",
    "    return entropy\n",
    "\n",
    "def ganancia_entropy(instancias, etiquetas_rama_izquierda, etiquetas_rama_derecha):\n",
    "    \n",
    "    ganancia_previa = entropy(etiquetas_rama_izquierda + etiquetas_rama_derecha)\n",
    "    entropy_izq = gini(etiquetas_rama_izquierda)\n",
    "    \n",
    "    proporcion_izq = (len(etiquetas_rama_izquierda)/len(instancias))\n",
    "    proporcion_der = (len(etiquetas_rama_derecha)/len(instancias))\n",
    "    \n",
    "    entropy_der = gini(etiquetas_rama_derecha)\n",
    "    ganancia_entropia = ganancia_previa - ((entropy_izq*proporcion_izq + entropy_der*proporcion_der)/2)\n",
    "    return ganancia_entropia\n",
    "\n",
    "    \n",
    "def get_ganancia(instancias, etiquetas_rama_izquierda, etiquetas_rama_derecha, criterion):\n",
    "    \n",
    "    if criterion == \"gini\":\n",
    "        return ganancia_gini(instancias, etiquetas_rama_izquierda, etiquetas_rama_derecha)\n",
    "    else:\n",
    "        return ganancia_entropy(instancias, etiquetas_rama_izquierda, etiquetas_rama_derecha)\n",
    "    \n",
    "\n",
    "def partir_segun(pregunta, instancias, etiquetas, criterion):\n",
    "\n",
    "    try:\n",
    "        float(pregunta.valor)\n",
    "        return partir_segun_attr_numerico(pregunta, instancias, etiquetas, criterion)\n",
    "    except:\n",
    "        return partir_segun_attr_discreto(pregunta, instancias, etiquetas, criterion)\n",
    "    \n",
    "def partir_segun_attr_discreto(pregunta, instancias, etiquetas, criterion):\n",
    "    \n",
    "    # Esta función debe separar instancias y etiquetas según si cada instancia cumple o no con la pregunta (ver método 'cumple')\n",
    "    # COMPLETAR (recomendamos utilizar máscaras para este punto)\n",
    "    \n",
    "    instancias_cumplen, etiquetas_cumplen, instancias_no_cumplen, etiquetas_no_cumplen = list(), list(), list(), list()\n",
    "\n",
    "    index = 0\n",
    "    for x, instance in instancias.iterrows():\n",
    "\n",
    "        if instance[pregunta.atributo] == pregunta.valor:\n",
    "            instancias_cumplen.append(instance)\n",
    "            etiquetas_cumplen.append(etiquetas[index])\n",
    "        else:\n",
    "            instancias_no_cumplen.append(instance)\n",
    "            etiquetas_no_cumplen.append(etiquetas[index])\n",
    "        index += 1\n",
    "    return pd.DataFrame(instancias_cumplen), etiquetas_cumplen, pd.DataFrame(instancias_no_cumplen), etiquetas_no_cumplen\n",
    "\n",
    "def partir_segun_attr_numerico(pregunta, instancias, etiquetas, criterion):\n",
    "    \n",
    "    instancias_copy = instancias.copy()\n",
    "    instancias_copy[\"___tmp___\"] = etiquetas\n",
    "    \n",
    "    cut = pregunta.valor\n",
    "    cumplen = instancias_copy[instancias_copy[pregunta.atributo] < cut]\n",
    "    no_cumplen = instancias_copy[instancias_copy[pregunta.atributo] >= cut]\n",
    "    etiquetas_cumplen = list(cumplen[\"___tmp___\"])\n",
    "    etiquetas_no_cumplen = list(no_cumplen[\"___tmp___\"])\n",
    "    del cumplen[\"___tmp___\"]\n",
    "    del no_cumplen[\"___tmp___\"]\n",
    "    \n",
    "    return cumplen, etiquetas_cumplen, no_cumplen, etiquetas_no_cumplen \n",
    "\n",
    "def encontrar_mejor_atributo_y_corte(instancias, etiquetas, criterion):\n",
    "    \n",
    "    max_ganancia = 0\n",
    "    mejor_pregunta = None\n",
    "    for columna in instancias.columns:\n",
    "        \n",
    "        try:\n",
    "            for valor in set(instancias[columna]): #asegurarse que son valores numericos\n",
    "                float(valor)\n",
    "            \n",
    "            instancias_tmp = instancias.copy()\n",
    "            instancias_tmp[\"___tmp___\"] = etiquetas\n",
    "            instancias_tmp.sort_values(columna)\n",
    "            etiquetas_tmp = instancias_tmp[\"___tmp___\"]\n",
    "            del instancias_tmp[\"___tmp___\"]\n",
    "            \n",
    "            if len(instancias_tmp) == 1:\n",
    "                pregunta = Pregunta(columna, 0) #da igual\n",
    "                _, etiquetas_rama_izquierda, _, etiquetas_rama_derecha = partir_segun_attr_numerico(pregunta, instancias_tmp, etiquetas_tmp, criterion)\n",
    "                ganancia = get_ganancia(instancias, etiquetas_rama_izquierda, etiquetas_rama_derecha, criterion)\n",
    "                if ganancia > max_ganancia:\n",
    "                    max_ganancia = ganancia\n",
    "                    mejor_pregunta = pregunta\n",
    "            else:\n",
    "                \n",
    "                instancia_anterior = None\n",
    "                mejor_ganancia_hasta_ahora = 0\n",
    "                for x, una_instancia in instancias_tmp.iterrows():\n",
    "                    if instancia_anterior is None:\n",
    "                        instancia_anterior = una_instancia\n",
    "                    else:\n",
    "                        cut = (instancia_anterior[columna] + una_instancia[columna])/2\n",
    "                        #num_pregunta += 1\n",
    "                        #print(num_pregunta)\n",
    "                        pregunta = Pregunta(columna, cut)\n",
    "                        _, etiquetas_rama_izquierda, _, etiquetas_rama_derecha = partir_segun_attr_numerico(pregunta, instancias_tmp, etiquetas_tmp, criterion)\n",
    "                        ganancia = get_ganancia(instancias, etiquetas_rama_izquierda, etiquetas_rama_derecha, criterion)\n",
    "                        if ganancia > max_ganancia:\n",
    "                            max_ganancia = ganancia\n",
    "                            mejor_pregunta = pregunta\n",
    "                        instancia_anterior = una_instancia\n",
    "        \n",
    "        except:\n",
    "            for valor in set(instancias[columna]):\n",
    "                # Probando corte para atributo y valor\n",
    "                pregunta = Pregunta(columna, valor)\n",
    "                _, etiquetas_rama_izquierda, _, etiquetas_rama_derecha = partir_segun_attr_discreto(pregunta, instancias, etiquetas, criterion)\n",
    "\n",
    "                ganancia = get_ganancia(instancias, etiquetas_rama_izquierda, etiquetas_rama_derecha, criterion)\n",
    "\n",
    "                if ganancia > max_ganancia:\n",
    "                    max_ganancia = ganancia\n",
    "                    mejor_pregunta = pregunta\n",
    "      \n",
    "    return max_ganancia, mejor_pregunta\n",
    "\n",
    "def predecir(arbol, x_t):\n",
    "    \n",
    "    if isinstance(arbol, Hoja):\n",
    "        max = 0\n",
    "        return_value = None\n",
    "        for key,value in arbol.cuentas.items():\n",
    "            if value > max:\n",
    "                return_value = key\n",
    "                max = value\n",
    "        return return_value\n",
    "    \n",
    "    else:\n",
    "        attr = arbol.pregunta.atributo\n",
    "        val = arbol.pregunta.valor\n",
    "        try:\n",
    "            float(val)\n",
    "            if x_t[attr] < val:\n",
    "                return predecir(arbol.sub_arbol_izquierdo, x_t)    \n",
    "            else:\n",
    "                return predecir(arbol.sub_arbol_derecho, x_t)\n",
    "        except:\n",
    "            if(x_t.loc[attr]) == val:\n",
    "                return predecir(arbol.sub_arbol_izquierdo, x_t)\n",
    "            else:\n",
    "                return predecir(arbol.sub_arbol_derecho, x_t)\n",
    "\n",
    "        \n",
    "class CustomDecisionTreeClassifier(): \n",
    "    def __init__(self, criterion = \"gini\", max_depth=None):\n",
    "        self.arbol = None\n",
    "        if criterion != \"gini\" and criterion != \"entropy\":\n",
    "            raise Exception(\"Criterio desconocido\")\n",
    "        \n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.arbol = construir_arbol(pd.DataFrame(X_train), y_train, criterion=self.criterion, max_depth=self.max_depth)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for x_t in X_test:\n",
    "            x_t_df = pd.DataFrame([x_t]).iloc[0]\n",
    "            prediction = predecir(self.arbol, x_t_df) \n",
    "            predictions.append(prediction)\n",
    "        return predictions\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        \n",
    "        accuracy = sum(y_i == y_j for (y_i, y_j) in zip(y_pred, y_test)) / len(y_test)\n",
    "        return accuracy\n",
    "        \n",
    "def imprimir_arbol(arbol, spacing=\"\"):\n",
    "    \n",
    "    if isinstance(arbol, MiClasificadorArbol):\n",
    "        imprimir_arbol(arbol.arbol)\n",
    "        return\n",
    "    \n",
    "    if isinstance(arbol, Hoja):\n",
    "        print (spacing + \"Hoja:\", arbol.cuentas)\n",
    "        return\n",
    "\n",
    "    print (spacing + str(arbol.pregunta))\n",
    "\n",
    "    print (spacing + '--> True:')\n",
    "    imprimir_arbol(arbol.sub_arbol_izquierdo, spacing + \"  \")\n",
    "\n",
    "    print (spacing + '--> False:')\n",
    "    imprimir_arbol(arbol.sub_arbol_derecho, spacing + \"  \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 1 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validación)</th>\n",
       "      <th>AUC ROC (training)</th>\n",
       "      <th>AUC ROC (validación)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Permutación</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.905</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>0.7003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.9110</td>\n",
       "      <td>0.6305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.8417</td>\n",
       "      <td>0.6932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>0.7365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.8726</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy (training)  Accuracy (validación)  AUC ROC (training)  \\\n",
       "Permutación                                                                   \n",
       "1                          0.905                   0.70              0.9072   \n",
       "2                          0.910                   0.70              0.9110   \n",
       "3                          0.840                   0.70              0.8417   \n",
       "4                          0.875                   0.74              0.8763   \n",
       "5                          0.875                   0.64              0.8726   \n",
       "\n",
       "             AUC ROC (validación)  \n",
       "Permutación                        \n",
       "1                          0.7003  \n",
       "2                          0.6305  \n",
       "3                          0.6932  \n",
       "4                          0.7365  \n",
       "5                          0.6400  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "accuracies_training = []\n",
    "accuracies_validation = []\n",
    "aucs_training = []\n",
    "aucs_validation = []\n",
    "\n",
    "# Puede serles de utilidad tener a X_dev e y_dev como matrices de numpy directamente:\n",
    "X_dev_np = np.array(X_dev)\n",
    "y_dev_np = np.array(y_dev).ravel()\n",
    "\n",
    "########################################################\n",
    "## AQUI VA SU CODIGO \n",
    "## Objetivo: accuracies_training, accuracies_validation, aucs_training y aucs_validation asignados\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "for train_index, test_index in kf.split(X_dev):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X_dev_np[train_index], X_dev_np[test_index]\n",
    "    y_train, y_test = y_dev_np[train_index], y_dev_np[test_index]\n",
    "    \n",
    "    arbol = CustomDecisionTreeClassifier(max_depth=3)\n",
    "    arbol.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_test = arbol.predict(X_test)\n",
    "    y_pred_train = arbol.predict(X_train)\n",
    "    \n",
    "    ac_test=sklearn.metrics.accuracy_score(y_test, y_pred_test, normalize=True, sample_weight=None)\n",
    "    ac_train=sklearn.metrics.accuracy_score(y_train, y_pred_train, normalize=True, sample_weight=None)\n",
    "    accuracies_validation.append(ac_test)\n",
    "    accuracies_training.append(ac_train)\n",
    "    \n",
    "    roc_auc_test=sklearn.metrics.roc_auc_score(y_test, y_pred_test, sample_weight=None)\n",
    "    roc_auc_train=sklearn.metrics.roc_auc_score(y_train, y_pred_train, sample_weight=None)\n",
    "    aucs_training.append(roc_auc_train)\n",
    "    aucs_validation.append(roc_auc_test)\n",
    "\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(1,6))\n",
    "df.index.name = \"Permutación\"\n",
    "                  \n",
    "df[\"Accuracy (training)\"] = accuracies_training     # cambiar por accuracies_training\n",
    "df[\"Accuracy (validación)\"] = accuracies_validation   # cambiar por accuracies_validation\n",
    "df[\"AUC ROC (training)\"] = aucs_training     # cambiar por aucs_training\n",
    "df[\"AUC ROC (validación)\"] = aucs_validation    # [\"-\"] * 5 cambiar por aucs_validation\n",
    "\n",
    "\n",
    "display(HTML(\"<h3> TABLA 1 </h3>\"))\n",
    "display(df)\n",
    "\n",
    "# Descomentar las siguientes líneas para graficar el resultado\n",
    "df.plot(kind=\"bar\")\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 2 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altura máxima</th>\n",
       "      <th>Criterio de evaluación de corte</th>\n",
       "      <th>AUC ROC promedio (training)</th>\n",
       "      <th>AUC ROC promedio (validación)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>0.6801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.9789</td>\n",
       "      <td>0.6487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.6368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>0.6801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.9789</td>\n",
       "      <td>0.6487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.6368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Altura máxima Criterio de evaluación de corte  AUC ROC promedio (training)  \\\n",
       "0             3                            Gini                       0.8818   \n",
       "1             5                            Gini                       0.9789   \n",
       "2     Inifinito                            Gini                       0.9968   \n",
       "3             3         Ganancia de Información                       0.8818   \n",
       "4             5         Ganancia de Información                       0.9789   \n",
       "5     Inifinito         Ganancia de Información                       0.9968   \n",
       "\n",
       "   AUC ROC promedio (validación)  \n",
       "0                         0.6801  \n",
       "1                         0.6487  \n",
       "2                         0.6368  \n",
       "3                         0.6801  \n",
       "4                         0.6487  \n",
       "5                         0.6368  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultados_training = []\n",
    "resultados_validation = []\n",
    "\n",
    "########################################################\n",
    "## AQUI VA SU CODIGO \n",
    "## Objetivo: resultados_training y resultados_validation asignadas\n",
    "#\n",
    "## Recomendamos seguir el siguiente esquema:\n",
    "np.random.seed(SEED)\n",
    "for criterio in [\"gini\", \"entropy\"]:\n",
    "     for altura in [3, 5, None]:\n",
    "        \n",
    "        lista_aucs_train = []\n",
    "        lista_aucs_test = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(X_dev):\n",
    "            #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            X_train, X_test = X_dev_np[train_index], X_dev_np[test_index]\n",
    "            y_train, y_test = y_dev_np[train_index], y_dev_np[test_index]\n",
    "\n",
    "            arbol = CustomDecisionTreeClassifier(max_depth=altura, criterion=criterio)\n",
    "            arbol.fit(X_train, y_train)\n",
    "\n",
    "            y_pred_test = arbol.predict(X_test)\n",
    "            y_pred_train = arbol.predict(X_train)\n",
    "\n",
    "            #ac_test=sklearn.metrics.accuracy_score(y_test, y_pred_test, normalize=True, sample_weight=None)\n",
    "            #ac_train=sklearn.metrics.accuracy_score(y_train, y_pred_train, normalize=True, sample_weight=None)\n",
    "            #accuracies_validation.append(ac_test)\n",
    "            #accuracies_training.append(ac_train)  \n",
    "            \n",
    "            #EN EL PDF DICE ACURACY, ACA FIGURA AUC ROC\n",
    "            \n",
    "            roc_auc_test=sklearn.metrics.roc_auc_score(y_test, y_pred_test, sample_weight=None)\n",
    "            roc_auc_train=sklearn.metrics.roc_auc_score(y_train, y_pred_train, sample_weight=None)\n",
    "            lista_aucs_train.append(roc_auc_train)\n",
    "            lista_aucs_test.append(roc_auc_test)\n",
    "                \n",
    "\n",
    "        resultados_training.append( np.mean(lista_aucs_train) )\n",
    "        resultados_validation.append( np.mean(lista_aucs_test) )\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(0,6))\n",
    "\n",
    "df[\"Altura máxima\"] = [3, 5, \"Inifinito\"] * 2\n",
    "df[\"Criterio de evaluación de corte\"] = [\"Gini\"] * 3 + [\"Ganancia de Información\"] * 3\n",
    "df[\"AUC ROC promedio (training)\"] = resultados_training # reemplazar por resultados_training\n",
    "df[\"AUC ROC promedio (validación)\"] = resultados_validation # reemplazar por resultados_validation\n",
    "\n",
    "   \n",
    "display(HTML(\"<h3> TABLA 2 </h3>\"))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Comparación de algoritmos\n",
    "\n",
    "\n",
    "Se pide explorar distintas combinaciones de algoritmos de aprendizaje e hiperparámetros, de manera de buscar una performance óptima. Para este ejercicio es necesario que evalúen posibilidades utilizando la técnica de Grid Search. Como métrica de performance, usar siempre el área bajo la curva (AUC ROC) resultante de 5-fold cross-validation. \n",
    "\n",
    "Algoritmos a probar: KNN, árboles de decisión, LDA, Naive Bayes y SVM. Hiperparámetros: Revisar la documentación de cada uno para la búsqueda de combinaciones prometedoras.  \n",
    "\n",
    "Se pide generar un reporte que contenga: \n",
    "\n",
    "1. Una descripción de las distintas combinaciones consideradas y su performance asociada (las que consideren relevantes, con al menos la mejor combinación para cada algoritmo). \n",
    "\n",
    "1. Una breve explicación de los factores que creen que produjeron dicho resultado. \n",
    "\n",
    "En este punto evaluaremos tanto los hiperparámetros elegidos como las conclusiones relacionadas a por qué piensan que ciertos algoritmos funcionan mejor que otros para estos datos. \n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "**EJERCICIO EXTRA**: Utilizar RandomizedSearchCV con rangos de parámetros que contengan a los utilizados en el GridSearch. Analizar si se encontraron mejores combinaciones de parámetros que no hayan sido tenidas en cuenta con el GridSearch y cuál fue la diferencia de tiempo de ejecución. \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def top_resultados(grid, top=5):\n",
    "    ## Si quieren, pueden utilizar esta función para imprimir las mejores combinaciones de su grid\n",
    "    print(\"Top {} combinaciones\".format(top))\n",
    "    df = pd.DataFrame(grid.cv_results_[\"params\"])\n",
    "    df[\"mean_score_validation\"] = grid.cv_results_[\"mean_test_score\"]\n",
    "    df[\"mean_score_training\"] = grid.cv_results_[\"mean_train_score\"]\n",
    "    display(df.sort_values(by=\"mean_score_validation\", ascending=False).head(top))\n",
    "\n",
    "########################################################\n",
    "## AQUI VA SU CODIGO \n",
    "## Objetivo: comparar y explorar distintas combinaciones de parámetros para los algoritmos importados arriba\n",
    "\n",
    "X_eval_np = np.array(X_eval)\n",
    "y_eval_np = np.array(y_eval).ravel()\n",
    "X_dev_np = np.array(X_dev)\n",
    "y_dev_np = np.array(y_dev).ravel()\n",
    "\n",
    "X_train=X_dev_np\n",
    "X_test=X_eval_np\n",
    "y_train=y_dev_np\n",
    "y_test=y_eval_np\n",
    "\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def GridSearch(model, tuned_parameters):\n",
    "    scores = ['roc_auc']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(model, tuned_parameters, cv=5,\n",
    "                           scoring='%s' % score)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        #print(\"Detailed classification report:\")\n",
    "        #print()\n",
    "        #print(\"The model is trained on the full development set.\")\n",
    "        #print(\"The scores are computed on the full evaluation set.\")\n",
    "        #print()\n",
    "        #y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        #print(classification_report(y_true, y_pred))\n",
    "        #print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'p': 1, 'n_neighbors': 51, 'weights': 'distance'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.707 (+/-0.153) for {'p': 1, 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.707 (+/-0.153) for {'p': 1, 'n_neighbors': 1, 'weights': 'distance'}\n",
      "0.708 (+/-0.070) for {'p': 2, 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.708 (+/-0.070) for {'p': 2, 'n_neighbors': 1, 'weights': 'distance'}\n",
      "0.866 (+/-0.081) for {'p': 1, 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "0.871 (+/-0.086) for {'p': 1, 'n_neighbors': 11, 'weights': 'distance'}\n",
      "0.867 (+/-0.098) for {'p': 2, 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "0.872 (+/-0.098) for {'p': 2, 'n_neighbors': 11, 'weights': 'distance'}\n",
      "0.874 (+/-0.106) for {'p': 1, 'n_neighbors': 21, 'weights': 'uniform'}\n",
      "0.876 (+/-0.108) for {'p': 1, 'n_neighbors': 21, 'weights': 'distance'}\n",
      "0.878 (+/-0.113) for {'p': 2, 'n_neighbors': 21, 'weights': 'uniform'}\n",
      "0.880 (+/-0.110) for {'p': 2, 'n_neighbors': 21, 'weights': 'distance'}\n",
      "0.876 (+/-0.108) for {'p': 1, 'n_neighbors': 31, 'weights': 'uniform'}\n",
      "0.878 (+/-0.109) for {'p': 1, 'n_neighbors': 31, 'weights': 'distance'}\n",
      "0.877 (+/-0.098) for {'p': 2, 'n_neighbors': 31, 'weights': 'uniform'}\n",
      "0.880 (+/-0.096) for {'p': 2, 'n_neighbors': 31, 'weights': 'distance'}\n",
      "0.875 (+/-0.111) for {'p': 1, 'n_neighbors': 41, 'weights': 'uniform'}\n",
      "0.878 (+/-0.108) for {'p': 1, 'n_neighbors': 41, 'weights': 'distance'}\n",
      "0.879 (+/-0.136) for {'p': 2, 'n_neighbors': 41, 'weights': 'uniform'}\n",
      "0.881 (+/-0.132) for {'p': 2, 'n_neighbors': 41, 'weights': 'distance'}\n",
      "0.884 (+/-0.123) for {'p': 1, 'n_neighbors': 51, 'weights': 'uniform'}\n",
      "0.885 (+/-0.121) for {'p': 1, 'n_neighbors': 51, 'weights': 'distance'}\n",
      "0.871 (+/-0.134) for {'p': 2, 'n_neighbors': 51, 'weights': 'uniform'}\n",
      "0.875 (+/-0.134) for {'p': 2, 'n_neighbors': 51, 'weights': 'distance'}\n",
      "0.877 (+/-0.125) for {'p': 1, 'n_neighbors': 61, 'weights': 'uniform'}\n",
      "0.880 (+/-0.122) for {'p': 1, 'n_neighbors': 61, 'weights': 'distance'}\n",
      "0.876 (+/-0.119) for {'p': 2, 'n_neighbors': 61, 'weights': 'uniform'}\n",
      "0.877 (+/-0.118) for {'p': 2, 'n_neighbors': 61, 'weights': 'distance'}\n",
      "0.874 (+/-0.129) for {'p': 1, 'n_neighbors': 71, 'weights': 'uniform'}\n",
      "0.876 (+/-0.129) for {'p': 1, 'n_neighbors': 71, 'weights': 'distance'}\n",
      "0.870 (+/-0.122) for {'p': 2, 'n_neighbors': 71, 'weights': 'uniform'}\n",
      "0.874 (+/-0.123) for {'p': 2, 'n_neighbors': 71, 'weights': 'distance'}\n",
      "0.874 (+/-0.119) for {'p': 1, 'n_neighbors': 81, 'weights': 'uniform'}\n",
      "0.875 (+/-0.117) for {'p': 1, 'n_neighbors': 81, 'weights': 'distance'}\n",
      "0.868 (+/-0.130) for {'p': 2, 'n_neighbors': 81, 'weights': 'uniform'}\n",
      "0.872 (+/-0.131) for {'p': 2, 'n_neighbors': 81, 'weights': 'distance'}\n",
      "0.867 (+/-0.125) for {'p': 1, 'n_neighbors': 91, 'weights': 'uniform'}\n",
      "0.868 (+/-0.120) for {'p': 1, 'n_neighbors': 91, 'weights': 'distance'}\n",
      "0.865 (+/-0.126) for {'p': 2, 'n_neighbors': 91, 'weights': 'uniform'}\n",
      "0.867 (+/-0.127) for {'p': 2, 'n_neighbors': 91, 'weights': 'distance'}\n",
      "0.865 (+/-0.126) for {'p': 1, 'n_neighbors': 101, 'weights': 'uniform'}\n",
      "0.866 (+/-0.126) for {'p': 1, 'n_neighbors': 101, 'weights': 'distance'}\n",
      "0.865 (+/-0.129) for {'p': 2, 'n_neighbors': 101, 'weights': 'uniform'}\n",
      "0.868 (+/-0.132) for {'p': 2, 'n_neighbors': 101, 'weights': 'distance'}\n",
      "0.866 (+/-0.127) for {'p': 1, 'n_neighbors': 111, 'weights': 'uniform'}\n",
      "0.866 (+/-0.127) for {'p': 1, 'n_neighbors': 111, 'weights': 'distance'}\n",
      "0.862 (+/-0.132) for {'p': 2, 'n_neighbors': 111, 'weights': 'uniform'}\n",
      "0.866 (+/-0.134) for {'p': 2, 'n_neighbors': 111, 'weights': 'distance'}\n",
      "0.868 (+/-0.136) for {'p': 1, 'n_neighbors': 121, 'weights': 'uniform'}\n",
      "0.868 (+/-0.137) for {'p': 1, 'n_neighbors': 121, 'weights': 'distance'}\n",
      "0.862 (+/-0.138) for {'p': 2, 'n_neighbors': 121, 'weights': 'uniform'}\n",
      "0.865 (+/-0.133) for {'p': 2, 'n_neighbors': 121, 'weights': 'distance'}\n",
      "\n",
      "CPU times: user 10 s, sys: 484 ms, total: 10.5 s\n",
      "Wall time: 10.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'n_neighbors':range(1, len(X_test)//2, 10), 'weights':[\"uniform\", \"distance\"], 'p':range(1, 3)}]\n",
    "%time GridSearch(KNeighborsClassifier(), tuned_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 2, 'criterion': 'entropy'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.702 (+/-0.087) for {'max_depth': 1, 'criterion': 'gini'}\n",
      "0.753 (+/-0.145) for {'max_depth': 2, 'criterion': 'gini'}\n",
      "0.736 (+/-0.204) for {'max_depth': 3, 'criterion': 'gini'}\n",
      "0.644 (+/-0.116) for {'max_depth': 4, 'criterion': 'gini'}\n",
      "0.654 (+/-0.124) for {'max_depth': 5, 'criterion': 'gini'}\n",
      "0.692 (+/-0.120) for {'max_depth': 1, 'criterion': 'entropy'}\n",
      "0.765 (+/-0.096) for {'max_depth': 2, 'criterion': 'entropy'}\n",
      "0.741 (+/-0.096) for {'max_depth': 3, 'criterion': 'entropy'}\n",
      "0.722 (+/-0.121) for {'max_depth': 4, 'criterion': 'entropy'}\n",
      "0.726 (+/-0.104) for {'max_depth': 5, 'criterion': 'entropy'}\n",
      "\n",
      "CPU times: user 1.69 s, sys: 12 ms, total: 1.7 s\n",
      "Wall time: 1.71 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'max_depth':range(1,6) , 'criterion': [\"gini\", \"entropy\"]}]\n",
    "%time GridSearch(DecisionTreeClassifier(), tuned_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'shrinkage': 'auto', 'solver': 'lsqr'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.538 (+/-0.070) for {'solver': 'svd'}\n",
      "0.465 (+/-0.198) for {'shrinkage': None, 'solver': 'lsqr'}\n",
      "0.875 (+/-0.107) for {'shrinkage': 'auto', 'solver': 'lsqr'}\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'shrinkage': 'auto', 'solver': 'lsqr'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.538 (+/-0.070) for {'solver': 'svd'}\n",
      "0.465 (+/-0.198) for {'shrinkage': None, 'solver': 'lsqr'}\n",
      "0.875 (+/-0.107) for {'shrinkage': 'auto', 'solver': 'lsqr'}\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'shrinkage': 'auto', 'solver': 'lsqr'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.538 (+/-0.070) for {'solver': 'svd'}\n",
      "0.465 (+/-0.198) for {'shrinkage': None, 'solver': 'lsqr'}\n",
      "0.875 (+/-0.107) for {'shrinkage': 'auto', 'solver': 'lsqr'}\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'shrinkage': 'auto', 'solver': 'lsqr'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.538 (+/-0.070) for {'solver': 'svd'}\n",
      "0.465 (+/-0.198) for {'shrinkage': None, 'solver': 'lsqr'}\n",
      "0.875 (+/-0.107) for {'shrinkage': 'auto', 'solver': 'lsqr'}\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'shrinkage': 'auto', 'solver': 'lsqr'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.538 (+/-0.070) for {'solver': 'svd'}\n",
      "0.465 (+/-0.198) for {'shrinkage': None, 'solver': 'lsqr'}\n",
      "0.875 (+/-0.107) for {'shrinkage': 'auto', 'solver': 'lsqr'}\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'shrinkage': 'auto', 'solver': 'lsqr'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.538 (+/-0.070) for {'solver': 'svd'}\n",
      "0.465 (+/-0.198) for {'shrinkage': None, 'solver': 'lsqr'}\n",
      "0.875 (+/-0.107) for {'shrinkage': 'auto', 'solver': 'lsqr'}\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'shrinkage': 'auto', 'solver': 'lsqr'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.538 (+/-0.070) for {'solver': 'svd'}\n",
      "0.465 (+/-0.198) for {'shrinkage': None, 'solver': 'lsqr'}\n",
      "0.875 (+/-0.107) for {'shrinkage': 'auto', 'solver': 'lsqr'}\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'shrinkage': 'auto', 'solver': 'lsqr'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.538 (+/-0.070) for {'solver': 'svd'}\n",
      "0.465 (+/-0.198) for {'shrinkage': None, 'solver': 'lsqr'}\n",
      "0.875 (+/-0.107) for {'shrinkage': 'auto', 'solver': 'lsqr'}\n",
      "\n",
      "1.83 s ± 391 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#tuned_parameters = [{'solver':['svd','lsqr']}]\n",
    "#tuned_parameters = [{'solver':['lsqr'],'shrinkage':[None,'auto']}]\n",
    "#param_grid = [{'solver':['svd']},{'solver':['lsqr'],'shrinkage':[None,'auto']}]\n",
    "\n",
    "tuned_parameters= [{'solver':['svd']},{'solver':['lsqr'],'shrinkage':[None,'auto']}]\n",
    "\n",
    "%timeit GridSearch(LinearDiscriminantAnalysis(), tuned_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.865 (+/-0.119) for {'priors': None}\n",
      "0.865 (+/-0.119) for {'priors': [0.1, 0.9]}\n",
      "0.865 (+/-0.119) for {'priors': [0.2, 0.8]}\n",
      "0.865 (+/-0.119) for {'priors': [0.3, 0.7]}\n",
      "0.865 (+/-0.119) for {'priors': [0.4, 0.6]}\n",
      "0.865 (+/-0.119) for {'priors': [0.5, 0.5]}\n",
      "0.865 (+/-0.119) for {'priors': [0.6, 0.4]}\n",
      "0.865 (+/-0.119) for {'priors': [0.7, 0.3]}\n",
      "0.865 (+/-0.119) for {'priors': [0.8, 0.2]}\n",
      "0.865 (+/-0.119) for {'priors': [0.9, 0.1]}\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.865 (+/-0.119) for {'priors': None}\n",
      "0.865 (+/-0.119) for {'priors': [0.1, 0.9]}\n",
      "0.865 (+/-0.119) for {'priors': [0.2, 0.8]}\n",
      "0.865 (+/-0.119) for {'priors': [0.3, 0.7]}\n",
      "0.865 (+/-0.119) for {'priors': [0.4, 0.6]}\n",
      "0.865 (+/-0.119) for {'priors': [0.5, 0.5]}\n",
      "0.865 (+/-0.119) for {'priors': [0.6, 0.4]}\n",
      "0.865 (+/-0.119) for {'priors': [0.7, 0.3]}\n",
      "0.865 (+/-0.119) for {'priors': [0.8, 0.2]}\n",
      "0.865 (+/-0.119) for {'priors': [0.9, 0.1]}\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.865 (+/-0.119) for {'priors': None}\n",
      "0.865 (+/-0.119) for {'priors': [0.1, 0.9]}\n",
      "0.865 (+/-0.119) for {'priors': [0.2, 0.8]}\n",
      "0.865 (+/-0.119) for {'priors': [0.3, 0.7]}\n",
      "0.865 (+/-0.119) for {'priors': [0.4, 0.6]}\n",
      "0.865 (+/-0.119) for {'priors': [0.5, 0.5]}\n",
      "0.865 (+/-0.119) for {'priors': [0.6, 0.4]}\n",
      "0.865 (+/-0.119) for {'priors': [0.7, 0.3]}\n",
      "0.865 (+/-0.119) for {'priors': [0.8, 0.2]}\n",
      "0.865 (+/-0.119) for {'priors': [0.9, 0.1]}\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.865 (+/-0.119) for {'priors': None}\n",
      "0.865 (+/-0.119) for {'priors': [0.1, 0.9]}\n",
      "0.865 (+/-0.119) for {'priors': [0.2, 0.8]}\n",
      "0.865 (+/-0.119) for {'priors': [0.3, 0.7]}\n",
      "0.865 (+/-0.119) for {'priors': [0.4, 0.6]}\n",
      "0.865 (+/-0.119) for {'priors': [0.5, 0.5]}\n",
      "0.865 (+/-0.119) for {'priors': [0.6, 0.4]}\n",
      "0.865 (+/-0.119) for {'priors': [0.7, 0.3]}\n",
      "0.865 (+/-0.119) for {'priors': [0.8, 0.2]}\n",
      "0.865 (+/-0.119) for {'priors': [0.9, 0.1]}\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.865 (+/-0.119) for {'priors': None}\n",
      "0.865 (+/-0.119) for {'priors': [0.1, 0.9]}\n",
      "0.865 (+/-0.119) for {'priors': [0.2, 0.8]}\n",
      "0.865 (+/-0.119) for {'priors': [0.3, 0.7]}\n",
      "0.865 (+/-0.119) for {'priors': [0.4, 0.6]}\n",
      "0.865 (+/-0.119) for {'priors': [0.5, 0.5]}\n",
      "0.865 (+/-0.119) for {'priors': [0.6, 0.4]}\n",
      "0.865 (+/-0.119) for {'priors': [0.7, 0.3]}\n",
      "0.865 (+/-0.119) for {'priors': [0.8, 0.2]}\n",
      "0.865 (+/-0.119) for {'priors': [0.9, 0.1]}\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.865 (+/-0.119) for {'priors': None}\n",
      "0.865 (+/-0.119) for {'priors': [0.1, 0.9]}\n",
      "0.865 (+/-0.119) for {'priors': [0.2, 0.8]}\n",
      "0.865 (+/-0.119) for {'priors': [0.3, 0.7]}\n",
      "0.865 (+/-0.119) for {'priors': [0.4, 0.6]}\n",
      "0.865 (+/-0.119) for {'priors': [0.5, 0.5]}\n",
      "0.865 (+/-0.119) for {'priors': [0.6, 0.4]}\n",
      "0.865 (+/-0.119) for {'priors': [0.7, 0.3]}\n",
      "0.865 (+/-0.119) for {'priors': [0.8, 0.2]}\n",
      "0.865 (+/-0.119) for {'priors': [0.9, 0.1]}\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.865 (+/-0.119) for {'priors': None}\n",
      "0.865 (+/-0.119) for {'priors': [0.1, 0.9]}\n",
      "0.865 (+/-0.119) for {'priors': [0.2, 0.8]}\n",
      "0.865 (+/-0.119) for {'priors': [0.3, 0.7]}\n",
      "0.865 (+/-0.119) for {'priors': [0.4, 0.6]}\n",
      "0.865 (+/-0.119) for {'priors': [0.5, 0.5]}\n",
      "0.865 (+/-0.119) for {'priors': [0.6, 0.4]}\n",
      "0.865 (+/-0.119) for {'priors': [0.7, 0.3]}\n",
      "0.865 (+/-0.119) for {'priors': [0.8, 0.2]}\n",
      "0.865 (+/-0.119) for {'priors': [0.9, 0.1]}\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.865 (+/-0.119) for {'priors': None}\n",
      "0.865 (+/-0.119) for {'priors': [0.1, 0.9]}\n",
      "0.865 (+/-0.119) for {'priors': [0.2, 0.8]}\n",
      "0.865 (+/-0.119) for {'priors': [0.3, 0.7]}\n",
      "0.865 (+/-0.119) for {'priors': [0.4, 0.6]}\n",
      "0.865 (+/-0.119) for {'priors': [0.5, 0.5]}\n",
      "0.865 (+/-0.119) for {'priors': [0.6, 0.4]}\n",
      "0.865 (+/-0.119) for {'priors': [0.7, 0.3]}\n",
      "0.865 (+/-0.119) for {'priors': [0.8, 0.2]}\n",
      "0.865 (+/-0.119) for {'priors': [0.9, 0.1]}\n",
      "\n",
      "447 ms ± 72.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'priors':[None,[0.1,0.9],[0.2,0.8],[0.3,0.7],[0.4,0.6],[0.5,0.5],[0.6,0.4],[0.7,0.3],[0.8,0.2],[0.9,0.1]]}]\n",
    "% timeit GridSearch(GaussianNB(), tuned_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.0014677992676220691}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.869 (+/-0.126) for {'C': 0.0001}\n",
      "0.871 (+/-0.126) for {'C': 0.0001467799267622069}\n",
      "0.874 (+/-0.121) for {'C': 0.00021544346900318845}\n",
      "0.878 (+/-0.120) for {'C': 0.00031622776601683794}\n",
      "0.879 (+/-0.115) for {'C': 0.00046415888336127773}\n",
      "0.883 (+/-0.111) for {'C': 0.0006812920690579609}\n",
      "0.885 (+/-0.109) for {'C': 0.001}\n",
      "0.886 (+/-0.102) for {'C': 0.0014677992676220691}\n",
      "0.883 (+/-0.100) for {'C': 0.002154434690031882}\n",
      "0.884 (+/-0.098) for {'C': 0.0031622776601683794}\n",
      "0.883 (+/-0.103) for {'C': 0.004641588833612777}\n",
      "0.876 (+/-0.101) for {'C': 0.006812920690579608}\n",
      "0.875 (+/-0.099) for {'C': 0.01}\n",
      "0.868 (+/-0.102) for {'C': 0.01467799267622069}\n",
      "0.864 (+/-0.108) for {'C': 0.021544346900318822}\n",
      "0.861 (+/-0.106) for {'C': 0.03162277660168379}\n",
      "0.854 (+/-0.109) for {'C': 0.046415888336127774}\n",
      "0.853 (+/-0.111) for {'C': 0.06812920690579609}\n",
      "0.851 (+/-0.109) for {'C': 0.1}\n",
      "0.849 (+/-0.109) for {'C': 0.1467799267622069}\n",
      "0.848 (+/-0.110) for {'C': 0.21544346900318823}\n",
      "0.849 (+/-0.109) for {'C': 0.31622776601683794}\n",
      "0.848 (+/-0.110) for {'C': 0.46415888336127775}\n",
      "0.848 (+/-0.111) for {'C': 0.6812920690579608}\n",
      "0.848 (+/-0.112) for {'C': 1.0}\n",
      "0.848 (+/-0.113) for {'C': 1.4677992676220675}\n",
      "0.848 (+/-0.112) for {'C': 2.154434690031882}\n",
      "0.848 (+/-0.110) for {'C': 3.1622776601683795}\n",
      "0.848 (+/-0.111) for {'C': 4.641588833612772}\n",
      "0.848 (+/-0.111) for {'C': 6.812920690579608}\n",
      "0.848 (+/-0.109) for {'C': 10.0}\n",
      "0.848 (+/-0.109) for {'C': 14.677992676220676}\n",
      "0.848 (+/-0.109) for {'C': 21.54434690031882}\n",
      "0.848 (+/-0.109) for {'C': 31.622776601683793}\n",
      "0.848 (+/-0.109) for {'C': 46.41588833612773}\n",
      "0.848 (+/-0.109) for {'C': 68.12920690579608}\n",
      "0.848 (+/-0.109) for {'C': 100.0}\n",
      "0.848 (+/-0.109) for {'C': 146.77992676220674}\n",
      "0.848 (+/-0.109) for {'C': 215.44346900318823}\n",
      "0.848 (+/-0.109) for {'C': 316.22776601683796}\n",
      "0.848 (+/-0.109) for {'C': 464.1588833612773}\n",
      "0.848 (+/-0.109) for {'C': 681.2920690579608}\n",
      "0.848 (+/-0.109) for {'C': 1000.0}\n",
      "0.848 (+/-0.109) for {'C': 1467.7992676220676}\n",
      "0.848 (+/-0.109) for {'C': 2154.4346900318824}\n",
      "0.848 (+/-0.109) for {'C': 3162.2776601683795}\n",
      "0.848 (+/-0.109) for {'C': 4641.588833612773}\n",
      "0.848 (+/-0.109) for {'C': 6812.920690579608}\n",
      "0.848 (+/-0.109) for {'C': 10000.0}\n",
      "\n",
      "CPU times: user 3.65 s, sys: 2.17 s, total: 5.82 s\n",
      "Wall time: 3.02 s\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.001539926526059492}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.885 (+/-0.109) for {'C': 0.001}\n",
      "0.886 (+/-0.107) for {'C': 0.0010491397291363103}\n",
      "0.885 (+/-0.106) for {'C': 0.0011006941712522092}\n",
      "0.885 (+/-0.109) for {'C': 0.0011547819846894581}\n",
      "0.884 (+/-0.109) for {'C': 0.001211527658628589}\n",
      "0.885 (+/-0.108) for {'C': 0.0012710617996147444}\n",
      "0.885 (+/-0.106) for {'C': 0.001333521432163324}\n",
      "0.885 (+/-0.108) for {'C': 0.0013990503141372943}\n",
      "0.886 (+/-0.102) for {'C': 0.0014677992676220691}\n",
      "0.887 (+/-0.100) for {'C': 0.001539926526059492}\n",
      "0.886 (+/-0.100) for {'C': 0.0016155980984398745}\n",
      "0.886 (+/-0.100) for {'C': 0.0016949881513903461}\n",
      "0.886 (+/-0.100) for {'C': 0.0017782794100389228}\n",
      "0.885 (+/-0.101) for {'C': 0.001865663578576913}\n",
      "0.885 (+/-0.100) for {'C': 0.0019573417814876598}\n",
      "0.884 (+/-0.100) for {'C': 0.002053525026457146}\n",
      "0.883 (+/-0.100) for {'C': 0.0021544346900318843}\n",
      "0.883 (+/-0.101) for {'C': 0.0022603030271419193}\n",
      "0.884 (+/-0.098) for {'C': 0.0023713737056616554}\n",
      "0.884 (+/-0.097) for {'C': 0.002487902367238837}\n",
      "0.884 (+/-0.098) for {'C': 0.0026101572156825357}\n",
      "0.884 (+/-0.098) for {'C': 0.0027384196342643613}\n",
      "0.884 (+/-0.099) for {'C': 0.0028729848333536655}\n",
      "0.885 (+/-0.098) for {'C': 0.003014162529877389}\n",
      "0.884 (+/-0.098) for {'C': 0.0031622776601683794}\n",
      "0.885 (+/-0.099) for {'C': 0.0033176711278428547}\n",
      "0.885 (+/-0.100) for {'C': 0.0034807005884284095}\n",
      "0.885 (+/-0.099) for {'C': 0.003651741272548377}\n",
      "0.885 (+/-0.101) for {'C': 0.003831186849557285}\n",
      "0.884 (+/-0.103) for {'C': 0.004019450333615123}\n",
      "0.884 (+/-0.104) for {'C': 0.004216965034285823}\n",
      "0.882 (+/-0.104) for {'C': 0.004424185553847914}\n",
      "0.883 (+/-0.103) for {'C': 0.004641588833612777}\n",
      "0.882 (+/-0.104) for {'C': 0.004869675251658631}\n",
      "0.882 (+/-0.104) for {'C': 0.005108969774506924}\n",
      "0.881 (+/-0.103) for {'C': 0.00536002316539179}\n",
      "0.879 (+/-0.103) for {'C': 0.005623413251903491}\n",
      "0.878 (+/-0.101) for {'C': 0.005899746255923559}\n",
      "0.878 (+/-0.102) for {'C': 0.006189658188912603}\n",
      "0.878 (+/-0.103) for {'C': 0.006493816315762113}\n",
      "0.876 (+/-0.101) for {'C': 0.006812920690579608}\n",
      "0.876 (+/-0.101) for {'C': 0.007147705767941853}\n",
      "0.875 (+/-0.100) for {'C': 0.007498942093324558}\n",
      "0.876 (+/-0.102) for {'C': 0.007867438076599394}\n",
      "0.876 (+/-0.101) for {'C': 0.008254041852680182}\n",
      "0.877 (+/-0.099) for {'C': 0.008659643233600654}\n",
      "0.876 (+/-0.099) for {'C': 0.009085175756516862}\n",
      "0.875 (+/-0.100) for {'C': 0.009531618832347872}\n",
      "0.875 (+/-0.099) for {'C': 0.01}\n",
      "\n",
      "CPU times: user 2.74 s, sys: 1.7 s, total: 4.45 s\n",
      "Wall time: 2.32 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "a=np.logspace(-4, 4, num=49, endpoint=True, base=10.0, dtype=None)\n",
    "tuned_parameters = [{'C':a}]\n",
    "%time GridSearch(LinearSVC(), tuned_parameters)\n",
    "\n",
    "a=np.logspace(-3, -2, num=49, endpoint=True, base=10.0, dtype=None)\n",
    "tuned_parameters = [{'C':a}]\n",
    "%time GridSearch(LinearSVC(), tuned_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones Grid Search\n",
    "\n",
    "KNN: Variamos la cantidad de vecinos, entre 1 y 121, peso unifrome y distancia, y p en 1 2 y 3\n",
    "{'n_neighbors': 51, 'p': 1, 'weights': 'distance'} : 0.885 (+/-0.121)\n",
    "\n",
    "Árboles: Variamos el criterio y la profundidad\n",
    "{'criterion': 'entropy', 'max_depth': 2} : 0.765 (+/-0.096)\n",
    "\n",
    "LDA: solver y shrinkage\n",
    "0.875 (+/-0.107) for {'shrinkage': 'auto', 'solver': 'lsqr'}\n",
    "\n",
    "GaussianNB: priors\n",
    "0.877 (+/-0.083) for {'priors': None}\n",
    "\n",
    "LinearSVC: C\n",
    "0.887 (+/-0.100) for {'C': 0.001539926526059492}\n",
    "\n",
    "Conclusiones: todos los métodos dan igual, excepto árboles. esto se puede deber a que el problema es linealmente separable, por lo que SVC termina siendo el mejor algoritmo con un C bajo. el limite alcanzado (~12% error) puede deberse al ruido inherente a los datos\n",
    "al ser separable en mas de una dimension, arboles no es muy bueno encontrando la frontera.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EJ EXTRA\n",
    "KNN: \n",
    "0.885 (+/-0.121) for {'weights': 'distance', 'p': 1, 'n_neighbors': 51}\n",
    "Wall time: 7.01 s\n",
    "GRID: Wall time: 7.56 s\n",
    "\n",
    "Arboles:\n",
    "0.765 (+/-0.096) for {'max_depth': 2, 'criterion': 'entropy'}\n",
    "Wall time: 1.89 s\n",
    "GRID: Wall time: 1.6 s\n",
    "\n",
    "SVC\n",
    "0.887 (+/-0.100) for {'C': 0.0015262013596464125}\n",
    "Wall time: 1.86 s\n",
    "GRID: Wall time: 1.82 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extra\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def RandomSearch(model, tuned_parameters, n_iter):\n",
    "    scores = ['roc_auc']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        clf = RandomizedSearchCV(model,param_distributions=tuned_parameters, n_iter=n_iter,cv=5,\n",
    "                           scoring='%s' % score, random_state = 1234)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        #print(\"Detailed classification report:\")\n",
    "        #print()\n",
    "        #print(\"The model is trained on the full development set.\")\n",
    "        #print(\"The scores are computed on the full evaluation set.\")\n",
    "        #print()\n",
    "        #y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        #print(classification_report(y_true, y_pred))\n",
    "        #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'p': 1, 'n_neighbors': 51, 'weights': 'distance'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.865 (+/-0.126) for {'p': 1, 'n_neighbors': 101, 'weights': 'uniform'}\n",
      "0.877 (+/-0.118) for {'p': 2, 'n_neighbors': 61, 'weights': 'distance'}\n",
      "0.867 (+/-0.127) for {'p': 2, 'n_neighbors': 91, 'weights': 'distance'}\n",
      "0.866 (+/-0.127) for {'p': 1, 'n_neighbors': 111, 'weights': 'uniform'}\n",
      "0.867 (+/-0.098) for {'p': 2, 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "0.862 (+/-0.132) for {'p': 2, 'n_neighbors': 111, 'weights': 'uniform'}\n",
      "0.878 (+/-0.109) for {'p': 1, 'n_neighbors': 31, 'weights': 'distance'}\n",
      "0.874 (+/-0.106) for {'p': 1, 'n_neighbors': 21, 'weights': 'uniform'}\n",
      "0.868 (+/-0.137) for {'p': 1, 'n_neighbors': 121, 'weights': 'distance'}\n",
      "0.874 (+/-0.123) for {'p': 2, 'n_neighbors': 71, 'weights': 'distance'}\n",
      "0.866 (+/-0.081) for {'p': 1, 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "0.885 (+/-0.121) for {'p': 1, 'n_neighbors': 51, 'weights': 'distance'}\n",
      "0.866 (+/-0.127) for {'p': 1, 'n_neighbors': 111, 'weights': 'distance'}\n",
      "0.865 (+/-0.133) for {'p': 2, 'n_neighbors': 121, 'weights': 'distance'}\n",
      "0.879 (+/-0.136) for {'p': 2, 'n_neighbors': 41, 'weights': 'uniform'}\n",
      "0.884 (+/-0.123) for {'p': 1, 'n_neighbors': 51, 'weights': 'uniform'}\n",
      "0.878 (+/-0.113) for {'p': 2, 'n_neighbors': 21, 'weights': 'uniform'}\n",
      "0.872 (+/-0.098) for {'p': 2, 'n_neighbors': 11, 'weights': 'distance'}\n",
      "0.877 (+/-0.098) for {'p': 2, 'n_neighbors': 31, 'weights': 'uniform'}\n",
      "0.878 (+/-0.108) for {'p': 1, 'n_neighbors': 41, 'weights': 'distance'}\n",
      "0.871 (+/-0.134) for {'p': 2, 'n_neighbors': 51, 'weights': 'uniform'}\n",
      "0.880 (+/-0.122) for {'p': 1, 'n_neighbors': 61, 'weights': 'distance'}\n",
      "0.876 (+/-0.129) for {'p': 1, 'n_neighbors': 71, 'weights': 'distance'}\n",
      "0.707 (+/-0.153) for {'p': 1, 'n_neighbors': 1, 'weights': 'distance'}\n",
      "0.872 (+/-0.131) for {'p': 2, 'n_neighbors': 81, 'weights': 'distance'}\n",
      "0.862 (+/-0.138) for {'p': 2, 'n_neighbors': 121, 'weights': 'uniform'}\n",
      "0.708 (+/-0.070) for {'p': 2, 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.875 (+/-0.117) for {'p': 1, 'n_neighbors': 81, 'weights': 'distance'}\n",
      "0.868 (+/-0.120) for {'p': 1, 'n_neighbors': 91, 'weights': 'distance'}\n",
      "0.874 (+/-0.119) for {'p': 1, 'n_neighbors': 81, 'weights': 'uniform'}\n",
      "0.867 (+/-0.125) for {'p': 1, 'n_neighbors': 91, 'weights': 'uniform'}\n",
      "0.707 (+/-0.153) for {'p': 1, 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.880 (+/-0.110) for {'p': 2, 'n_neighbors': 21, 'weights': 'distance'}\n",
      "0.708 (+/-0.070) for {'p': 2, 'n_neighbors': 1, 'weights': 'distance'}\n",
      "0.868 (+/-0.130) for {'p': 2, 'n_neighbors': 81, 'weights': 'uniform'}\n",
      "0.868 (+/-0.136) for {'p': 1, 'n_neighbors': 121, 'weights': 'uniform'}\n",
      "0.876 (+/-0.108) for {'p': 1, 'n_neighbors': 21, 'weights': 'distance'}\n",
      "0.875 (+/-0.111) for {'p': 1, 'n_neighbors': 41, 'weights': 'uniform'}\n",
      "0.871 (+/-0.086) for {'p': 1, 'n_neighbors': 11, 'weights': 'distance'}\n",
      "0.874 (+/-0.129) for {'p': 1, 'n_neighbors': 71, 'weights': 'uniform'}\n",
      "0.868 (+/-0.132) for {'p': 2, 'n_neighbors': 101, 'weights': 'distance'}\n",
      "0.865 (+/-0.129) for {'p': 2, 'n_neighbors': 101, 'weights': 'uniform'}\n",
      "0.870 (+/-0.122) for {'p': 2, 'n_neighbors': 71, 'weights': 'uniform'}\n",
      "0.876 (+/-0.119) for {'p': 2, 'n_neighbors': 61, 'weights': 'uniform'}\n",
      "0.866 (+/-0.126) for {'p': 1, 'n_neighbors': 101, 'weights': 'distance'}\n",
      "0.875 (+/-0.134) for {'p': 2, 'n_neighbors': 51, 'weights': 'distance'}\n",
      "0.880 (+/-0.096) for {'p': 2, 'n_neighbors': 31, 'weights': 'distance'}\n",
      "0.877 (+/-0.125) for {'p': 1, 'n_neighbors': 61, 'weights': 'uniform'}\n",
      "0.876 (+/-0.108) for {'p': 1, 'n_neighbors': 31, 'weights': 'uniform'}\n",
      "0.865 (+/-0.126) for {'p': 2, 'n_neighbors': 91, 'weights': 'uniform'}\n",
      "\n",
      "CPU times: user 7.88 s, sys: 620 ms, total: 8.5 s\n",
      "Wall time: 7.64 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = {'n_neighbors':range(1, len(X_test)//2, 10), 'weights':[\"uniform\", \"distance\"], 'p':range(1, 3)}\n",
    "%time RandomSearch(KNeighborsClassifier(), tuned_parameters,n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 3, 'criterion': 'gini'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.685 (+/-0.052) for {'max_depth': 9, 'criterion': 'gini'}\n",
      "0.753 (+/-0.145) for {'max_depth': 2, 'criterion': 'gini'}\n",
      "0.687 (+/-0.102) for {'max_depth': 11, 'criterion': 'entropy'}\n",
      "0.658 (+/-0.060) for {'max_depth': 5, 'criterion': 'gini'}\n",
      "0.673 (+/-0.184) for {'max_depth': 4, 'criterion': 'gini'}\n",
      "0.662 (+/-0.141) for {'max_depth': 8, 'criterion': 'gini'}\n",
      "0.716 (+/-0.090) for {'max_depth': 5, 'criterion': 'entropy'}\n",
      "0.679 (+/-0.116) for {'max_depth': 11, 'criterion': 'gini'}\n",
      "0.692 (+/-0.120) for {'max_depth': 1, 'criterion': 'entropy'}\n",
      "0.647 (+/-0.128) for {'max_depth': 14, 'criterion': 'gini'}\n",
      "0.757 (+/-0.203) for {'max_depth': 3, 'criterion': 'gini'}\n",
      "0.676 (+/-0.127) for {'max_depth': 12, 'criterion': 'entropy'}\n",
      "0.691 (+/-0.041) for {'max_depth': 13, 'criterion': 'entropy'}\n",
      "0.702 (+/-0.087) for {'max_depth': 1, 'criterion': 'gini'}\n",
      "0.676 (+/-0.036) for {'max_depth': 6, 'criterion': 'gini'}\n",
      "0.687 (+/-0.121) for {'max_depth': 9, 'criterion': 'entropy'}\n",
      "0.750 (+/-0.109) for {'max_depth': 3, 'criterion': 'entropy'}\n",
      "0.679 (+/-0.113) for {'max_depth': 10, 'criterion': 'entropy'}\n",
      "0.667 (+/-0.111) for {'max_depth': 12, 'criterion': 'gini'}\n",
      "0.681 (+/-0.067) for {'max_depth': 10, 'criterion': 'gini'}\n",
      "\n",
      "CPU times: user 3.75 s, sys: 0 ns, total: 3.75 s\n",
      "Wall time: 3.75 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = {'max_depth':range(1,15) , 'criterion': [\"gini\", \"entropy\"]}\n",
    "n_iter=20\n",
    "%time RandomSearch(DecisionTreeClassifier(), tuned_parameters,n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.0015025598101093456}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.877 (+/-0.100) for {'C': 0.00850666436052429}\n",
      "0.885 (+/-0.101) for {'C': 0.0038078147056072194}\n",
      "0.883 (+/-0.101) for {'C': 0.002192115377602205}\n",
      "0.884 (+/-0.103) for {'C': 0.004038369582315153}\n",
      "0.876 (+/-0.102) for {'C': 0.007845288992683828}\n",
      "0.876 (+/-0.101) for {'C': 0.006696505941218151}\n",
      "0.883 (+/-0.101) for {'C': 0.002108595328061282}\n",
      "0.885 (+/-0.100) for {'C': 0.003629573526144963}\n",
      "0.883 (+/-0.096) for {'C': 0.0025846046655082725}\n",
      "0.885 (+/-0.108) for {'C': 0.0012430567176970216}\n",
      "0.886 (+/-0.101) for {'C': 0.00172608576369937}\n",
      "0.884 (+/-0.109) for {'C': 0.0012084281186108957}\n",
      "0.875 (+/-0.100) for {'C': 0.009542008440816466}\n",
      "0.883 (+/-0.100) for {'C': 0.0021852614025497023}\n",
      "0.883 (+/-0.097) for {'C': 0.002551784930795491}\n",
      "0.884 (+/-0.109) for {'C': 0.001203928806587987}\n",
      "0.880 (+/-0.101) for {'C': 0.005432345079311948}\n",
      "0.878 (+/-0.102) for {'C': 0.006197662495415088}\n",
      "0.878 (+/-0.102) for {'C': 0.00627029498869139}\n",
      "0.881 (+/-0.103) for {'C': 0.005392713127988336}\n",
      "0.877 (+/-0.099) for {'C': 0.008611907391906634}\n",
      "0.877 (+/-0.099) for {'C': 0.008614088951442136}\n",
      "0.885 (+/-0.097) for {'C': 0.003118781431367158}\n",
      "0.882 (+/-0.104) for {'C': 0.00479674696532278}\n",
      "0.884 (+/-0.100) for {'C': 0.002305226625880903}\n",
      "0.885 (+/-0.107) for {'C': 0.0010920446169200447}\n",
      "0.886 (+/-0.099) for {'C': 0.0016698298748205494}\n",
      "0.886 (+/-0.100) for {'C': 0.001643622803578521}\n",
      "0.878 (+/-0.102) for {'C': 0.006333707696066611}\n",
      "0.878 (+/-0.101) for {'C': 0.0059889098183147004}\n",
      "0.884 (+/-0.098) for {'C': 0.0032123663521415147}\n",
      "0.879 (+/-0.102) for {'C': 0.0058236819934767235}\n",
      "0.886 (+/-0.101) for {'C': 0.001725489691780242}\n",
      "0.884 (+/-0.097) for {'C': 0.0024861306928731838}\n",
      "0.886 (+/-0.100) for {'C': 0.0016302421682693542}\n",
      "0.885 (+/-0.106) for {'C': 0.0013215123031089277}\n",
      "0.879 (+/-0.102) for {'C': 0.005769359629414668}\n",
      "0.878 (+/-0.101) for {'C': 0.006595355237507737}\n",
      "0.884 (+/-0.098) for {'C': 0.003194074513636341}\n",
      "0.887 (+/-0.100) for {'C': 0.0015025598101093456}\n",
      "0.884 (+/-0.103) for {'C': 0.004008722835908645}\n",
      "0.885 (+/-0.099) for {'C': 0.002954028657439477}\n",
      "0.885 (+/-0.109) for {'C': 0.0011642082172402036}\n",
      "0.882 (+/-0.103) for {'C': 0.005012299348445966}\n",
      "0.885 (+/-0.107) for {'C': 0.0010887053801183683}\n",
      "0.885 (+/-0.108) for {'C': 0.001390917697691263}\n",
      "0.884 (+/-0.107) for {'C': 0.0013733188390735803}\n",
      "0.885 (+/-0.106) for {'C': 0.0012965256938672809}\n",
      "0.882 (+/-0.104) for {'C': 0.004881090783341671}\n",
      "0.885 (+/-0.102) for {'C': 0.003967125912558048}\n",
      "\n",
      "CPU times: user 2.76 s, sys: 1.61 s, total: 4.38 s\n",
      "Wall time: 2.29 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "a=np.logspace(-3, -2, num=100000, endpoint=True, base=10.0, dtype=None)\n",
    "tuned_parameters = {'C':a}\n",
    "n_iter=50\n",
    "%time RandomSearch(LinearSVC(), tuned_parameters,n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: \n",
    "### Diagnóstico Sesgo-Varianza. \n",
    "\n",
    "En este punto, se pide inspeccionar dos de sus mejores modelos encontrados hasta ahora: el mejor modelo de tipo árbol de decisión y el mejor de tipo SVM. Para ello:\n",
    "\n",
    "1. Graficar curvas de complejidad para cada modelo, variando la profundidad en el caso de árboles, y el hiperparámetro C en el caso de SVM. Diagnosticar cómo afectan al sesgo y a la varianza esos dos hiperparámetros.\n",
    "2. Graficar curvas de aprendizaje para cada modelo. En base a estas curvas, sacar conclusiones sobre si los algoritmos parecen haber alcanzado su límite, o bien si aumentar la cantidad de datos debería ayudar.\n",
    "3. Construir un modelo RandomForest con 200 árboles. Explorar para qué sirve el hiperparámetro max_features y cómo afecta a la performance del algoritmo mediante una curva de complejidad. Explicar por qué creen que se dieron los resultados obtenidos. Por último, graficar una curva de aprendizaje sobre los parámetros elegidos para determinar si sería útil o no conseguir más datos (usar  grid search para encontrar una buena combinación de parámetros).  \n",
    "\n",
    "\n",
    "**Atención**: Tener en cuenta que debemos seguir utilizando ROC AUC como métrica para estas curvas.\n",
    "\n",
    "**ver**: http://scikit-learn.org/stable/modules/learning_curve.html#learning-curve\n",
    "\n",
    "----\n",
    "**EJERCICIO EXTRA:** Utilizar RandomizedSearchCV para explorar la performance del algoritmo de Gradient Boosting y comparar con los resultados obtenidos en el punto (c).\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb09a63f9e8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEYCAYAAACtEtpmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMys6i/zEcSkijQSjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb09a828eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Punto 1\n",
    "\n",
    "roc_auc_tree_train = []\n",
    "roc_auc_tree_test = []\n",
    "\n",
    "tree_lengths = np.arange(1, 20)\n",
    "\n",
    "for length in tree_lengths:\n",
    "\n",
    "    lista_aucs_train = []\n",
    "    lista_aucs_test = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_dev):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X_dev_np[train_index], X_dev_np[test_index]\n",
    "        y_train, y_test = y_dev_np[train_index], y_dev_np[test_index]\n",
    "\n",
    "        arbol = DecisionTreeClassifier(max_depth=length, criterion='gini')\n",
    "        arbol.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_test = arbol.predict(X_test)\n",
    "        y_pred_train = arbol.predict(X_train)\n",
    "\n",
    "        roc_auc_test=sklearn.metrics.roc_auc_score(y_test, y_pred_test, sample_weight=None)\n",
    "        roc_auc_train=sklearn.metrics.roc_auc_score(y_train, y_pred_train, sample_weight=None)\n",
    "        lista_aucs_train.append(roc_auc_train)\n",
    "        lista_aucs_test.append(roc_auc_test)\n",
    "\n",
    "\n",
    "    roc_auc_tree_train.append( np.mean(lista_aucs_train) )\n",
    "    roc_auc_tree_test.append( np.mean(lista_aucs_test) )\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(tree_lengths, roc_auc_tree_train, color = 'blue', label = 'datos de entrenamiento')\n",
    "plt.plot(tree_lengths, roc_auc_tree_test, color = 'red', label = 'datos de validación')\n",
    "plt.xlabel('Altura del árbol')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.title('Curva de complejidad: Árboles de decisión')\n",
    "plt.grid(True)\n",
    "plt.legend()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discusión\n",
    "\n",
    "En el caso de los árboles de decisión, el hiperparámetro que indica la complejidad es su altura; al permitir nodos más profundos, el modelo separa las instancias en un mayor número de regiones, de esa manera complejizándose. \n",
    "Al graficar la ROC AUC en función de esta complejidad para los datos de entrenamiento, vemos que la métrica aumenta hasta alcanzar un valor perfecto (cerca de la altura 5). Teniendo en cuenta que la misma métrica es bastante más baja sobre los datos de validación para esas alturas, podemos concluir que el modelo empieza a _overfittear_. Esto implica que se tiene un sesgo bajo para alturas grandes, pero también una alta varianza, ya que diferentes conjuntos de entrenamiento resultarán en modelos que se (sobre)ajustarán de manera diferente a sus datos. \n",
    "\n",
    "En cambio, para una altura baja, si existieran _predictores fuertes_ que separen bien a los datos se tendría una varianza baja, puesto que los diferentes árboles resultarían similares al utilizar estos predictores cerca de la raiz.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb09a6207f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEbCAYAAAArhqjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb09a719e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc_svm_train = []\n",
    "roc_auc_svm_test = []\n",
    "\n",
    "svm_c = np.logspace(-5, 2, 100)\n",
    "\n",
    "for c in svm_c:\n",
    "    \n",
    "    lista_aucs_train = []\n",
    "    lista_aucs_test = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_dev):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X_dev_np[train_index], X_dev_np[test_index]\n",
    "        y_train, y_test = y_dev_np[train_index], y_dev_np[test_index]\n",
    "\n",
    "        svm = LinearSVC(C=c)\n",
    "        svm.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_test = svm.predict(X_test)\n",
    "        y_pred_train = svm.predict(X_train)\n",
    "\n",
    "        roc_auc_test=sklearn.metrics.roc_auc_score(y_test, y_pred_test, sample_weight=None)\n",
    "        roc_auc_train=sklearn.metrics.roc_auc_score(y_train, y_pred_train, sample_weight=None)\n",
    "        lista_aucs_train.append(roc_auc_train)\n",
    "        lista_aucs_test.append(roc_auc_test)\n",
    "\n",
    "\n",
    "    roc_auc_svm_train.append( np.mean(lista_aucs_train) )\n",
    "    roc_auc_svm_test.append( np.mean(lista_aucs_test) )\n",
    "    \n",
    "plt.figure()\n",
    "plt.semilogx(svm_c, np.array(roc_auc_svm_train), color = 'blue', label = 'datos de entrenamiento')\n",
    "plt.semilogx(svm_c, np.array(roc_auc_svm_test), color = 'red', label = 'datos de validación')\n",
    "plt.xlabel('Hiperparámetro C')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.title('Curva de complejidad: Linear Vector Classifier')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discusión\n",
    "\n",
    "En el caso del SVM lineal, el hiperparámetro que cuantifica la complejidad del modelo es el $C$. Éste indica el \"presupuesto\" que se tiene para que instancias puedan caer dentro de un margen del hiperplano separador. Si se aumenta su valor, se permite que más instancias se ubiquen dentro de este margen. Esto hace al modelo más complejo, ya que habrán más opciones de separación. \n",
    "\n",
    "Estudiando la ROC AUC sobre datos de entrenamiento y validación en función de este hiperparámetro $C$, vemos un comportamiento similar al observado para los árboles de decisión. Se tiene un valor $\\left( C \\sim 10^{-2} \\right)$ a partir del cual esta métrica es perfecta para los datos de entrenamiento pero bastante inferior para los de validación.\n",
    "Nuevamente, para complejidad mayor (en este caso, un $C$ más grande) se obtienen modelos con menor sesgo pero mayor varianza. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punto 2\n",
    "\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb09a3022b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEYCAYAAACz2+rVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIUqUFIQQQpQoKQghhCh5Apt6lGdZYY3zAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb09a518518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nICIiMSUFERGJKSmIiEjs/wP6kDlQJh8tCQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb09a33f898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_sizes, train_scores_tree, valid_scores_tree = learning_curve(\n",
    "    DecisionTreeClassifier(max_depth=2, criterion='entropy'), X_dev_np, y_dev_np, train_sizes=range(5, 199, 5), cv=5, \n",
    "    scoring = 'roc_auc')\n",
    "\n",
    "#train_sizes, train_scores_tree, valid_scores_tree = learning_curve(\n",
    "#    DecisionTreeClassifier(max_depth=2, criterion='entropy'), X, y, train_sizes=range(10, 399, 10), cv=5, \n",
    "#    scoring = 'roc_auc')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_sizes, 1-np.mean(train_scores_tree, axis = 1), color = 'blue', label = 'Error de entrenamiento')\n",
    "plt.plot(train_sizes, 1-np.mean(valid_scores_tree, axis = 1), color = 'red', label = 'Error de validación')\n",
    "plt.ylim(0, 0.6)\n",
    "plt.xlabel('Datos de entrenamiento')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Curva de aprendizaje: Árboles de decisión')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "train_sizes, train_scores_svm, valid_scores_svm = learning_curve(\n",
    "    LinearSVC(C=0.0015), X_dev_np, y_dev_np, train_sizes=range(5, 199, 5), cv=5, \n",
    "    scoring = 'roc_auc')\n",
    "\n",
    "#train_sizes, train_scores_svm, valid_scores_svm = learning_curve(\n",
    "#    LinearSVC(C=0.0015), X, y,train_sizes=range(10, 399, 10), cv=5, \n",
    "#    scoring = 'roc_auc')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_sizes, 1-np.mean(train_scores_svm, axis = 1), color = 'blue', label = 'Error de entrenamiento')\n",
    "plt.plot(train_sizes, 1-np.mean(valid_scores_svm, axis = 1), color = 'red', label = 'Error de validación')\n",
    "plt.ylim(0,0.6)\n",
    "plt.xlabel('Datos de entrenamiento')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Curva de aprendizaje: Linear Vector Classifier')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discusión\n",
    "En el caso del árbol de decisión vemos que la varianza (en el gŕafico vista como la distancia entre las curvas de error de validación y entrenamiento) disminuye a medida que aumenta la cantidad de datos de entrenamiento. Por otro lado, vemos también que aumenta el sesgo, siendo éste el error sobre los datos de entrenamiento. Este aumento sólo es pronunciado _hasta los 100_ datos de entrenamiento, y luego parece mantenerse aproximadamente consante; mientras que el error de validación continúa disminuyendo en el mismo rango. Estos dos factores nos permiten pensar que al aumentar la cantidad de datos continuarán acercándose ambas curvas, ya que el error de validación baja y el de entrenamiento se mantiene. \n",
    "Entonces, podemos concluir que es conveniente aumentar la cantidad de datos para el entrenamiento; puesto que el sesgo se mantendrá y la varianza disminuirá. \n",
    "\n",
    "En cambio, para la SVM vemos otro comportamiento. El sesgo es relativamente bajo (en comparación con el árbol de decisión) y no parece aumentar notablemente. El error de validación disminuye ligeramente a medida que se incrementan los datos de entrenamiento; no obstante, su disminución se reduce al aumentar los datos. De esa forma, vemos que la varianza se achica gradualmente, pero parece estabilizarse al tomar el total de los datos. \n",
    "Por lo tanto, en este caso no consideramos que sea útil aumentar la cantidad de datos, pues ya parece llegarse al límite del algoritmo y no habrá mayor reducción de varianza.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Punto 3\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#forest = RandomForestClassifier(n_estimators = 200, max_features='auto')\n",
    "# max_features impone cuántos atributos (del total) se consideran al partir desde un nodo. El 'auto' es sqrt(n_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "roc_auc_forest_train = []\n",
    "roc_auc_forest_test = []\n",
    "\n",
    "max_features_list = np.arange(1,150,5)\n",
    "\n",
    "for max_features in max_features_list:\n",
    "        \n",
    "    lista_aucs_train = []\n",
    "    lista_aucs_test = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_dev):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X_dev_np[train_index], X_dev_np[test_index]\n",
    "        y_train, y_test = y_dev_np[train_index], y_dev_np[test_index]\n",
    "\n",
    "        forest = RandomForestClassifier(n_estimators=200, max_features=max_features)\n",
    "        forest.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_test = forest.predict(X_test)\n",
    "        y_pred_train = forest.predict(X_train)\n",
    "\n",
    "        roc_auc_test=sklearn.metrics.roc_auc_score(y_test, y_pred_test, sample_weight=None)\n",
    "        roc_auc_train=sklearn.metrics.roc_auc_score(y_train, y_pred_train, sample_weight=None)\n",
    "        lista_aucs_train.append(roc_auc_train)\n",
    "        lista_aucs_test.append(roc_auc_test)\n",
    "\n",
    "\n",
    "    roc_auc_forest_train.append( np.mean(lista_aucs_train) )\n",
    "    roc_auc_forest_test.append( np.mean(lista_aucs_test) )\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(max_features_list, np.array(roc_auc_forest_train), color = 'blue', label = 'datos de entrenamiento')\n",
    "plt.plot(max_features_list, np.array(roc_auc_forest_test), color = 'red', label = 'datos de validación')\n",
    "plt.xlabel('Máximo de atributos a considerar en cada nodo')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.title('Curva de complejidad: Random Forest')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discusión\n",
    "\n",
    "Para el caso del RandomForest, la complejidad del modelo viene dada por la cantidad de atributos disponibles en cada nodo de cada árbol. Mientras se permitan utilizar más atributos, aumentarán las posibles decisiones que tome cada árbol, y de ese modo la cantidad de parámetros libres.\n",
    "\n",
    "En primer lugar, podemos notar que la métrica ROC AUC tiene un valor óptimo sobre los datos de entrenamiento para cualquier valor de la complejidad, nuevamente con valores menores sobre los datos de validación. Este error sobre validación disminuye ligeramente al aumentar la cantidad de atributos disponibles, pero presenta cierta dispersión. \n",
    "\n",
    "Creemos que el constante valor perfecto de la ROC AUC sobre los datos de entrenamiento se debe a el bajo sesgo del algortimo, pues se utilizan árboles que pueden crecer profundo (lo cual resulta en un bajo sesgo para cada árbol). El promediado sobre el conjunto de árboles resulta en una reducción de la varianza. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'n_estimators':[200], 'max_features':range(1, 100, 5), 'max_depth':range(1,11)}]\n",
    "%time GridSearch(RandomForestClassifier(random_state=1234, n_jobs = -1), tuned_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores_forest, valid_scores_forest = learning_curve(\n",
    "    RandomForestClassifier(n_estimators=200, max_features=1, max_depth=5, n_jobs=-1), X_dev_np, y_dev_np, train_sizes=range(5, 199, 5), cv=5, \n",
    "    scoring = 'roc_auc', random_state=1234, n_jobs=-1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_sizes, 1-np.mean(train_scores_forest, axis = 1), color = 'blue', label = 'Error de entrenamiento')\n",
    "plt.plot(train_sizes, 1-np.mean(valid_scores_forest, axis = 1), color = 'red', label = 'Error de validación')\n",
    "#plt.ylim(0, 0.6)\n",
    "plt.xlabel('Datos de entrenamiento')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Curva de aprendizaje: Random Forest')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "#print(train_scores_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competencias\n",
    "\n",
    "La entrega del trabajo estará acompañada de una competencia en la cual deberán poner a prueba su mejor modelo y sobre todo, su capacidad para estimar sus resultados. \n",
    "\n",
    "Su tarea será estimar la performance (AUC ROC) que tendrá su mejor modelo en datos de evaluación (X_competencia). \n",
    "\n",
    "Para ello, deberán predecir las probabilidades de las distintas instancias con su modelo, enviarnos dichas probabilidades junto a una estimación con 4 decimales de cuál será el AUC ROC resultante y calcularemos el resultado real. El grupo que consiga acercarse más al valor real, será el grupo ganador.  \n",
    "\n",
    "Recomendamos no perder de vista esta competencia en el momento de separar los datos en los primeros puntos. \n",
    "\n",
    "Para esto, junto con la entrega del informe, deberán enviar un archivo en formato csv con las columnas “index” y “output” (ver ejemplo de archivo en: [y_competencia_ejemplo.csv](https://github.com/pbrusco/aa-notebooks/blob/master/TP1/y_competencia_ejemplo.csv)) y un valor esperado de AUC ROC. \n",
    "\n",
    "\n",
    "## Entrega\n",
    "- Contarán con un esqueleto en formato Jupyter Notebook en donde tendrán que completar las celdas faltantes (ya sea con explicaciones y gráficos o código). \n",
    "- El notebook final deberá ser entregado en formatos .html e .ipynb. Es necesario que los resultados puedan reproducirse al ejecutar todas las celdas en orden (Kernel - Restart and Run All) utilizando las bibliotecas requeridas en el archivo: requirements.txt del repositorio. \n",
    "- Tienen tiempo hasta las 23:59hs del día miércoles 17/10/2018. La entrega se debe realizar a través del campus virtual y debe contener el informe.\n",
    "- El trabajo deberá elaborarse en grupos de 3 personas.\n",
    "- Se podrán pedir pruebas de integridad y autoría; es decir, verificar que la salida solicitada es fruto del modelo presentado y que el modelo fue construido según lo requerido en este enunciado.\n",
    "- La evaluación será grupal y se basará en la calidad del informe (presentación, claridad, prolijidad); la originalidad, practicidad y coherencia técnica de la solución; la corrección y solidez de las pruebas realizadas.\n",
    "- En el primer parcial se incluirá una pregunta sobre la solución entregada. Esa pregunta no influirá en la nota del parcial, pero sí en la nota individual del TP1.\n",
    "- La participación en la competencia es obligatoria. De todas maneras, el resultado no incidirán en la nota de la materia.\n",
    "- Los ejercicios extra son opcionales para aprobar el TP, pero son obligatorios para promocionar la materia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
